{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b90230c8-8434-44de-a310-aa13b6116668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]])\n"
     ]
    }
   ],
   "source": [
    "# torch tests\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Example(nn.Module):\n",
    "    def __init__(self, vocab_size, feature_size):\n",
    "        super(Example, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, feature_size)\n",
    "        self.layers = nn.TransformerEncoderLayer(d_model=feature_size, nhead=8)\n",
    "        self.transformer = nn.TransformerEncoder(self.layers, num_layers=6)\n",
    "        self.decoder = nn.Linear(feature_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # X shape: [seq_len, batch_size]\n",
    "        print('x.shape initial', x.shape)\n",
    "        x = self.embedding(x)\n",
    "        # X shape: [seq_len, batch_size, feature_size]\n",
    "        print('self.embedding(x)',x.shape)\n",
    "        x = self.transformer(x)\n",
    "        # X shape: [seq_len, batch_size, feature_size]\n",
    "        print('self.transformer(x)', x.shape)\n",
    "        x = self.decoder(x)\n",
    "        # X shape: [seq_len, batc_size, vocab_size]\n",
    "        print('self.decoder(x)', x.shape)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Example(10, 512)\n",
    "src = torch.LongTensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]).view(10, 1)\n",
    "print(src)\n",
    "# model(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b53cbba-eebb-49ec-b16a-fc812dcbc1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " tensor([[[ 0.,  1.],\n",
      "         [ 2.,  3.]],\n",
      "\n",
      "        [[ 4.,  5.],\n",
      "         [ 6.,  7.]],\n",
      "\n",
      "        [[ 8.,  9.],\n",
      "         [10., 11.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 5.],\n",
       "         [6., 7.]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(12).view(3,2,2).float()\n",
    "print('a:\\n',a)\n",
    "a.mean(0, keepdim = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnightly",
   "language": "python",
   "name": "dlnightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

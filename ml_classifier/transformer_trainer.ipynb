{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7217f6c2-4c4c-4e5c-9bb6-8687ed8f5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import re\n",
    "import sys\n",
    "from datetime import timedelta\n",
    "# from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f95fcad-56ab-43b6-a50d-317152f7e186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>Subclass2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500</td>\n",
       "      <td>Crop(Double)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loc_id  Subclass2019\n",
       "0         0    Plantation\n",
       "1         1  Crop(Single)\n",
       "2         2  Crop(Single)\n",
       "3         3  Crop(Single)\n",
       "4         4    Plantation\n",
       "..      ...           ...\n",
       "496     496  Crop(Single)\n",
       "497     497  Crop(Single)\n",
       "498     498    Plantation\n",
       "499     499    Plantation\n",
       "500     500  Crop(Double)\n",
       "\n",
       "[501 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "proj_paths = [\"/Users/gopal/Google Drive/_Research/Research projects/ML/manclassify/app_data/Thailand\",\n",
    "              \"/Users/gopalpenny/Library/CloudStorage/GoogleDrive-gopalpenny@gmail.com/My Drive/_Research/Research projects/ML/manclassify/app_data/Thailand\"]\n",
    "\n",
    "proj_path = [path for path in proj_paths if os.path.exists(path)][0]\n",
    "\n",
    "class_path = os.path.join(proj_path,\"Thailand_classification\")\n",
    "ts_path = os.path.join(proj_path,\"Thailand_download_timeseries\")\n",
    "# pd.read_csv(\"\n",
    "os.listdir(class_path)\n",
    "\n",
    "loc_id = 0\n",
    "\n",
    "s2_csv_name = f\"pt_ts_loc{loc_id}_s2.csv\"\n",
    "s2_csv_name\n",
    "\n",
    "class_colname = 'Subclass2019'\n",
    "\n",
    "proj_normpath = os.path.normpath(proj_path)\n",
    "proj_dirname = proj_normpath.split(os.sep)[-1]\n",
    "proj_name = re.sub(\"_classification$\",\"\",proj_dirname)\n",
    "class_path = os.path.join(proj_path, proj_name + \"_classification\")\n",
    "ts_path = os.path.join(proj_path, proj_name + \"_download_timeseries\")\n",
    "pt_classes = pd.read_csv(os.path.join(class_path,\"location_classification.csv\"))\n",
    "pt_classes = pt_classes[['loc_id', class_colname]].dropna()\n",
    "\n",
    "pt_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadc6355-df65-4834-b219-1d3d6ead823f",
   "metadata": {},
   "source": [
    "## Generate the torch tensor dataset\n",
    "\n",
    "### Define function to read timeseries\n",
    "\n",
    "* Read timeseries\n",
    "* Filter timeseries to date range (+/- 60 days)\n",
    "* Remove observations with clouds\n",
    "* Take the mean value for each day (occurs when multiple overpasses happen on the same day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32be994-4f4d-4666-9e96-9424cc71f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep dataset\n",
    "date_range = pd.to_datetime(['2019-06-01','2020-05-31'])\n",
    "\n",
    "def prep_s2_loc(loc_id, date_range, proj_path):\n",
    "    ts_path = os.path.join(proj_path,\"Thailand_download_timeseries\")\n",
    "    s2_csv_name = f\"pt_ts_loc{loc_id}_s2.csv\"\n",
    "    s2_csv_path = os.path.join(ts_path, s2_csv_name)\n",
    "    s2_ts = pd.read_csv(s2_csv_path)\n",
    "\n",
    "    # extract dates from image ids\n",
    "    s2_ts['datestr'] = [re.sub(\"(^[0-9]+)[a-zA-Z].*\",\"\\\\1\",x) for x in s2_ts.image_id]\n",
    "    s2_ts['date'] = pd.to_datetime(s2_ts.datestr, format = \"%Y%m%d\")\n",
    "\n",
    "    # subset to cloud-free days AND within date_range\n",
    "    s2_ts = s2_ts[(s2_ts.date >= date_range[0] - timedelta(days = 60)) & \n",
    "                  (s2_ts.date <= date_range[1] + timedelta(days = 60)) & \n",
    "                  (s2_ts.cloudmask == 0)]\n",
    "\n",
    "    # calculate day from startday\n",
    "    date_diff = (s2_ts.date - date_range[0])\n",
    "    s2_ts['day'] = [x.days for x in date_diff]\n",
    "    s2_ts['loc_id'] = loc_id\n",
    "\n",
    "    # select only predictor and position columns, return tensor\n",
    "    s2_ts_x = s2_ts[['loc_id','day','B8','B4','B3','B2']]\n",
    "    return s2_ts_x\n",
    "\n",
    "# s2_ts_loc125 = prep_s2_loc(125, date_range, proj_path)\n",
    "# s2_ts_loc125.groupby(['loc_id','day'],as_index = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336b48f-e6ff-468b-95cf-a1396e0e1768",
   "metadata": {},
   "source": [
    "### Get the torch tensor dataset (prep and save OR read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ac523f-49d7-4427-8d02-85e905ab73f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from ipywidgets import IntProgress\n",
    "# from IPython.display import display\n",
    "\n",
    "if os.path.exists(os.path.join(proj_path, 's2_ts_prepped.pt')):\n",
    "    loc_ts_tor = torch.load(os.path.join(proj_path, 's2_ts_prepped.pt'))\n",
    "    \n",
    "else:\n",
    "    # f = IntProgress(min=0, max=pt_classes.shape[0]) # instantiate the bar\n",
    "    display(f) # display the bar\n",
    "    \n",
    "    s2_ts_list = []\n",
    "    loc_id_list = []\n",
    "    for i in np.arange(pt_classes.shape[0]):\n",
    "        # loc_id = 499\n",
    "        # print(loc_id)\n",
    "        loc_id = pt_classes.loc_id.iloc[i]\n",
    "        # loc_id_list.append(loc_id)\n",
    "        s2_ts_loc = prep_s2_loc(loc_id, date_range, proj_path)\n",
    "        s2_ts_loc = s2_ts_loc.groupby(['loc_id','day'],as_index = False).mean()\n",
    "        s2_ts_tor = torch.tensor(s2_ts_loc.to_numpy())\n",
    "        s2_ts_list.append(s2_ts_tor)\n",
    "        # f.value += 1\n",
    "        \n",
    "    loc_ts_tor = torch.cat(s2_ts_list)\n",
    "\n",
    "    torch.save(loc_ts_tor, os.path.join(proj_path, 's2_ts_prepped.pt'))\n",
    "\n",
    "sys.getsizeof(loc_ts_tor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87657506-61f2-446c-ab16-6d6a4b200b16",
   "metadata": {},
   "source": [
    "### Prep the dataset tensors\n",
    "\n",
    "* Subset to training classes (crops & plantations)\n",
    "* Check max number of rows\n",
    "* Normalize & center\n",
    "* Split loc_id into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7b06a55-3c55-42e7-91fa-6ca3ea412559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All classes\n",
      "              loc_id\n",
      "Subclass2019        \n",
      "Crop(Double)      68\n",
      "Crop(Single)     278\n",
      "Forest             3\n",
      "Golf               1\n",
      "Mixed             20\n",
      "Plantation       109\n",
      "Unsure            17\n",
      "Urban              1\n",
      "Water              4\n",
      "\n",
      "Training dataset (pt_classes_ag)\n",
      "      loc_id  Subclass2019\n",
      "0         0    Plantation\n",
      "1         1  Crop(Single)\n",
      "2         2  Crop(Single)\n",
      "3         3  Crop(Single)\n",
      "4         4    Plantation\n",
      "..      ...           ...\n",
      "496     496  Crop(Single)\n",
      "497     497  Crop(Single)\n",
      "498     498    Plantation\n",
      "499     499    Plantation\n",
      "500     500  Crop(Double)\n",
      "\n",
      "[455 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('All classes')\n",
    "print(pt_classes.groupby('Subclass2019').count())\n",
    "\n",
    "train_classes = ['Crop(Double)','Crop(Single)','Plantation']\n",
    "pt_classes_ag = pt_classes[pt_classes['Subclass2019'].isin(train_classes)]\n",
    "print('\\nTraining dataset (pt_classes_ag)\\n',pt_classes_ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a727f0-a8c6-415c-b482-e19f70c5f571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of observations for any loc_id\n",
      "     loc_id  num_obs\n",
      "481     481       94\n"
     ]
    }
   ],
   "source": [
    "loc_ts_tor = loc_ts_tor[(loc_ts_tor[:,1] >= -30) & (loc_ts_tor[:,1] <= 395)]\n",
    "\n",
    "row_means= loc_ts_tor.mean(dim = 1)#.shape #.unsqueeze(0).repeat(5,1)\n",
    "loc_ts_tor = loc_ts_tor[~torch.isnan(row_means)]\n",
    "col_means= loc_ts_tor.mean(dim = 0)#.shape #.unsqueeze(0).repeat(5,1)\n",
    "col_std= loc_ts_tor.std(dim = 0)#.shape #.unsqueeze(0).repeat(5,1)\n",
    "col_means[[0,1]] = 0\n",
    "col_std[[0,1]] = 1\n",
    "\n",
    "loc_ts_tor_std = col_std.unsqueeze(0).repeat(loc_ts_tor.shape[0],1)\n",
    "loc_ts_tor_mean = col_means.unsqueeze(0).repeat(loc_ts_tor.shape[0],1)\n",
    "\n",
    "loc_ts_norm = (loc_ts_tor - loc_ts_tor_mean) / loc_ts_tor_std\n",
    "\n",
    "# get max of number of observations per location\n",
    "# idx = np.arange(loc_ts_norm.shape[0])\n",
    "loc_id = np.unique(loc_ts_norm[:,0])\n",
    "num_obs = pd.DataFrame({'loc_id' : np.unique(loc_ts_norm[:,0]).astype('int')})\n",
    "num_obs['num_obs'] = [loc_ts_norm[loc_ts_norm[:,0]==i,:].shape[0] for i in num_obs['loc_id']]\n",
    "print(\"Max number of observations for any loc_id\")\n",
    "print(num_obs.iloc[[num_obs['num_obs'].idxmax()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd6b44a2-91e1-4bfd-8b55-cdba3b3f1f09",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3013741568.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/js/4lzq4_rd12ndjrhf15w_jfrw0000gn/T/ipykernel_53608/3013741568.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print('Training (loc_train.groupby('Subclass2019').count())\\n', loc_train.groupby('Subclass2019').count())\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "loc_train = pt_classes_ag.groupby('Subclass2019', group_keys = False).apply(lambda x: x.sample(frac = 0.8))\n",
    "loc_train['n'] = loc_train.groupby('Subclass2019')['loc_id'].transform(len)\n",
    "loc_train['weight'] = loc_train.shape[0] / loc_train['n'] \n",
    "\n",
    "loc_test = pt_classes_ag[~pt_classes_ag['loc_id'].isin(loc_train.loc_id)]\n",
    "print('Training (loc_train summary)\\n', loc_train.groupby('Subclass2019').count())\n",
    "print('\\nTesting (loc_test summary)\\n', loc_test.groupby('Subclass2019').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bdda10b-384d-45fa-96d5-e83ec73a93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>Subclass2019</th>\n",
       "      <th>n</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>54</td>\n",
       "      <td>6.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>54</td>\n",
       "      <td>6.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>54</td>\n",
       "      <td>6.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>54</td>\n",
       "      <td>6.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>54</td>\n",
       "      <td>6.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>482</td>\n",
       "      <td>Plantation</td>\n",
       "      <td>87</td>\n",
       "      <td>4.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>Plantation</td>\n",
       "      <td>87</td>\n",
       "      <td>4.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Plantation</td>\n",
       "      <td>87</td>\n",
       "      <td>4.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>380</td>\n",
       "      <td>Plantation</td>\n",
       "      <td>87</td>\n",
       "      <td>4.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>Plantation</td>\n",
       "      <td>87</td>\n",
       "      <td>4.172414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loc_id  Subclass2019   n    weight\n",
       "171     171  Crop(Double)  54  6.722222\n",
       "41       41  Crop(Double)  54  6.722222\n",
       "134     134  Crop(Double)  54  6.722222\n",
       "395     395  Crop(Double)  54  6.722222\n",
       "48       48  Crop(Double)  54  6.722222\n",
       "..      ...           ...  ..       ...\n",
       "482     482    Plantation  87  4.172414\n",
       "120     120    Plantation  87  4.172414\n",
       "17       17    Plantation  87  4.172414\n",
       "380     380    Plantation  87  4.172414\n",
       "161     161    Plantation  87  4.172414\n",
       "\n",
       "[363 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "848fb5a1-70fc-4de4-8d58-ebaea6adaa25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class s2Dataset(Dataset):\n",
    "    \"\"\"Sentinel 2 dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x_train (tensor): contains loc_id and predictors as columns, s2 observations as rows\n",
    "            y_train (tensor): contains loc_id as rows, weights and class as 1-hot columns\n",
    "        \"\"\"\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        # self.proj_path = proj_path\n",
    "        # proj_normpath = os.path.normpath(proj_path)\n",
    "        # proj_dirname = proj_normpath.split(os.sep)[-1]\n",
    "        # self.proj_name = re.sub(\"_classification$\",\"\",proj_dirname)\n",
    "        # self.class_path = os.path.join(proj_path, self.proj_name + \"_classification\")\n",
    "        # self.ts_path = os.path.join(proj_path, self.proj_name + \"_download_timeseries\")\n",
    "        # self.pt_classes = pd.read_csv(os.path.join(self.class_path,\"location_classification.csv\"))\n",
    "        # self.pt_classes = classes[['loc_id', class_colname]].dropna()\n",
    "        # self.classes = pd.unique(self.pt_classes[class_colname])\n",
    "        # self.labels = self.pt_classes.assign(val = 1).pivot_table(columns = class_colname, index = 'loc_id', values = 'val', fill_value= 0)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get loc_id\n",
    "        loc_id = self.y_train[idx,0]\n",
    "        self.last_loc_id = loc_id\n",
    "        \n",
    "        # select location id\n",
    "        x_loc = self.x_train[self.x_train[:,0]==loc_id]\n",
    "        x = x_loc[:,1:] # remove loc_id column\n",
    "        \n",
    "        # get one-hot encoding for the point as tensor\n",
    "        y = torch.tensor(y_train[idx,2:])\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90680b25-01d0-4c4e-972d-034ea76b5b03",
   "metadata": {
    "tags": []
   },
   "source": [
    "### get training data\n",
    "\n",
    "* `y_train` directly from `loc_train` & pivot\n",
    "* `x_train` from `loc_ts_norm`, subset to `y_train[:,0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58824da7-827c-430e-9954-0b03a8a80277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get y_train values from loc_train\n",
    "y_train_df = (loc_train.assign(val = 1) \\\n",
    "  .pivot_table(columns = class_colname, index = ['loc_id','weight'], values = 'val', fill_value= 0) \\\n",
    "  .reset_index(['loc_id','weight']))\n",
    "y_train = y_train_df.to_numpy()\n",
    "print('y_train:\\n',y_train)\n",
    "\n",
    "y_train = y_train_df.to_numpy()\n",
    "\n",
    "# get x_train values from loc_ts_norm (based on loc_id)\n",
    "x_train = loc_ts_norm[torch.isin(loc_ts_norm[:,0],torch.tensor(y_train[:,0]).to(torch.float64)),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631a3d7-b607-474a-a6ef-6a8751ef1aad",
   "metadata": {},
   "source": [
    "### build pytorch dataset: `s2_dateset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ba874b-c3df-4eed-9511-8103df128f75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train:\n",
      " [[  0.           4.17241379   0.           0.           1.        ]\n",
      " [  1.           1.63513514   0.           1.           0.        ]\n",
      " [  5.           6.72222222   1.           0.           0.        ]\n",
      " ...\n",
      " [497.           1.63513514   0.           1.           0.        ]\n",
      " [498.           4.17241379   0.           0.           1.        ]\n",
      " [499.           4.17241379   0.           0.           1.        ]]\n",
      "x example (idx=1): day, B8, B4, B3, B2\n",
      " tensor([[-1.2000e+01,  7.3413e-01,  2.8951e+00,  3.5055e+00,  3.1997e+00],\n",
      "        [-7.0000e+00, -9.7997e-01,  7.5053e-01,  3.9384e-01,  4.4937e-01],\n",
      "        [ 1.0800e+02, -7.0083e-01, -1.1618e+00, -1.1620e+00, -1.1403e+00],\n",
      "        [ 1.1300e+02, -7.6956e-01, -1.2326e+00, -1.2688e+00, -1.2431e+00],\n",
      "        [ 1.2800e+02, -6.0825e-01, -1.0004e+00, -8.2507e-01, -8.3469e-01],\n",
      "        [ 1.3800e+02, -9.3459e-02, -8.5873e-01, -4.8542e-01, -2.1763e-01],\n",
      "        [ 1.4300e+02, -5.8861e-01, -1.1552e+00, -1.1455e+00, -1.0903e+00],\n",
      "        [ 1.5300e+02, -1.1169e-01, -1.1256e+00, -9.3737e-01, -9.4341e-01],\n",
      "        [ 1.6300e+02, -6.6808e-02, -1.1272e+00, -8.4972e-01, -9.9630e-01],\n",
      "        [ 1.6800e+02, -2.9685e-01, -8.6367e-01, -7.5933e-01, -9.3753e-01],\n",
      "        [ 1.7300e+02, -6.8540e-01, -5.0953e-01, -6.2511e-01, -5.6142e-01],\n",
      "        [ 1.7800e+02, -5.8581e-01,  4.8040e-01,  4.8710e-02,  2.6251e-02],\n",
      "        [ 1.8300e+02, -8.1024e-01,  4.3428e-01, -1.1564e-01, -7.3654e-02],\n",
      "        [ 1.8800e+02, -5.6617e-01,  5.6441e-01,  6.2406e-02,  8.6204e-03],\n",
      "        [ 1.9300e+02, -3.1649e-01,  7.7854e-01,  2.0758e-01,  2.4957e-01],\n",
      "        [ 1.9800e+02, -3.4595e-01,  8.0160e-01,  2.9249e-01,  2.3194e-01],\n",
      "        [ 2.0300e+02, -4.2309e-01,  7.5218e-01,  3.5275e-01,  5.2871e-01],\n",
      "        [ 2.0800e+02, -1.4232e+00, -2.0330e-02, -6.9907e-01, -6.8483e-01],\n",
      "        [ 2.1800e+02, -9.2246e-01,  4.8370e-01, -8.8246e-02, -4.1332e-02],\n",
      "        [ 2.2300e+02, -3.3751e+00, -1.2631e+00, -1.9029e+00, -1.2696e+00],\n",
      "        [ 2.2800e+02, -1.1244e+00,  6.7312e-01,  4.1575e-01,  4.4056e-01],\n",
      "        [ 2.3300e+02, -1.0431e+00,  6.2206e-01,  6.2940e-01,  8.9013e-01],\n",
      "        [ 2.4300e+02, -9.0422e-01,  8.5595e-01,  8.4305e-01,  1.0429e+00],\n",
      "        [ 2.4800e+02, -6.8540e-01,  1.2908e+00,  1.2512e+00,  1.0811e+00],\n",
      "        [ 2.5300e+02, -7.8639e-01,  8.7407e-01,  1.1416e+00,  1.5895e+00],\n",
      "        [ 2.5800e+02, -6.2368e-01,  1.2612e+00,  1.2484e+00,  1.1369e+00],\n",
      "        [ 2.6300e+02, -5.9843e-01,  1.3073e+00,  1.3087e+00,  1.3779e+00],\n",
      "        [ 2.6800e+02, -8.0463e-01,  1.2677e+00,  1.2594e+00,  1.1869e+00],\n",
      "        [ 2.7300e+02, -4.6798e-01,  1.0635e+00,  1.6703e+00,  2.2858e+00],\n",
      "        [ 2.8300e+02, -3.7821e-01,  1.5132e+00,  2.4893e+00,  3.2996e+00],\n",
      "        [ 2.9800e+02, -3.0807e-01,  1.1376e+00,  1.7963e+00,  2.4386e+00],\n",
      "        [ 3.0300e+02, -4.2450e-01,  1.1360e+00,  1.6429e+00,  2.2653e+00],\n",
      "        [ 3.2300e+02, -1.0047e-01,  1.9184e+00,  1.9798e+00,  1.8422e+00],\n",
      "        [ 3.3800e+02,  2.7966e-01,  1.9826e+00,  2.1140e+00,  1.6894e+00],\n",
      "        [ 3.4300e+02,  1.3191e+00,  3.1521e+00,  3.6780e+00,  3.2291e+00],\n",
      "        [ 3.6300e+02, -5.5587e-02,  1.7800e+00,  1.7552e+00,  1.6747e+00],\n",
      "        [ 3.6800e+02, -5.0024e-01,  1.2941e+00,  1.5497e+00,  1.4778e+00]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([37, 5])\n",
      "\n",
      "\n",
      "y example (idx=1): crops(double) crops(single) plantation\n",
      " tensor([0., 1., 0.], dtype=torch.float64)\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "s2_dataset = s2Dataset(x_train = x_train, y_train = y_train)\n",
    "\n",
    "# example item in dataset\n",
    "idx_test = 1\n",
    "x, y = s2_dataset.__getitem__(idx_test)\n",
    "\n",
    "print(f'x example (idx={idx_test}): day, B8, B4, B3, B2\\n',x)\n",
    "print(x.shape)\n",
    "print(f'\\n\\ny example (idx={idx_test}): crops(double) crops(single) plantation\\n',y)\n",
    "print(y.shape)\n",
    "# sys.getsizeof(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298322ee-b1f3-42a9-a7c9-de79fb131fdc",
   "metadata": {},
   "source": [
    "### generate sampling weights for data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c911f46-100f-424d-9c1f-c9982d0cd300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>Subclass2019</th>\n",
       "      <th>n</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>54</td>\n",
       "      <td>6.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>54</td>\n",
       "      <td>6.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>54</td>\n",
       "      <td>6.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>54</td>\n",
       "      <td>6.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>54</td>\n",
       "      <td>6.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>482</td>\n",
       "      <td>Plantation</td>\n",
       "      <td>87</td>\n",
       "      <td>4.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>Plantation</td>\n",
       "      <td>87</td>\n",
       "      <td>4.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Plantation</td>\n",
       "      <td>87</td>\n",
       "      <td>4.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>380</td>\n",
       "      <td>Plantation</td>\n",
       "      <td>87</td>\n",
       "      <td>4.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>Plantation</td>\n",
       "      <td>87</td>\n",
       "      <td>4.172414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loc_id  Subclass2019   n    weight\n",
       "171     171  Crop(Double)  54  6.722222\n",
       "41       41  Crop(Double)  54  6.722222\n",
       "134     134  Crop(Double)  54  6.722222\n",
       "395     395  Crop(Double)  54  6.722222\n",
       "48       48  Crop(Double)  54  6.722222\n",
       "..      ...           ...  ..       ...\n",
       "482     482    Plantation  87  4.172414\n",
       "120     120    Plantation  87  4.172414\n",
       "17       17    Plantation  87  4.172414\n",
       "380     380    Plantation  87  4.172414\n",
       "161     161    Plantation  87  4.172414\n",
       "\n",
       "[363 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_train_n = loc_train\n",
    "loc_train_n['n'] = loc_train_n.groupby('Subclass2019')['loc_id'].transform(len)\n",
    "loc_train_n['weight'] = loc_train_n.shape[0] / loc_train_n['n'] \n",
    "loc_train_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1ad4e3d-3d90-45b7-8fcf-180c28fdcc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(s2_dataset, batch_size = 4, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a2bbd30-e297-47cf-a025-d8983de6c8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc3947-ba93-4b8c-81a1-75732d2cef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac10e44-7ccd-4f4e-ab48-255648980338",
   "metadata": {},
   "source": [
    "## Old S2 pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8801cb4f-7504-4665-bd51-91a431e0d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class s2Dataset(Dataset):\n",
    "#     \"\"\"Sentinel 2 dataset\"\"\"\n",
    "    \n",
    "#     def __init__(self, proj_path, class_colname):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             proj_path (string): path to manclassify project\n",
    "#         \"\"\"\n",
    "#         self.proj_path = proj_path\n",
    "#         proj_normpath = os.path.normpath(proj_path)\n",
    "#         proj_dirname = proj_normpath.split(os.sep)[-1]\n",
    "#         self.proj_name = re.sub(\"_classification$\",\"\",proj_dirname)\n",
    "#         self.class_path = os.path.join(proj_path, self.proj_name + \"_classification\")\n",
    "#         self.ts_path = os.path.join(proj_path, self.proj_name + \"_download_timeseries\")\n",
    "#         self.pt_classes = pd.read_csv(os.path.join(self.class_path,\"location_classification.csv\"))\n",
    "#         self.pt_classes = classes[['loc_id', class_colname]].dropna()\n",
    "#         # self.pt_classes['loc_id'] = self.pt_classes['loc_id'] + 10.5 # for testing index only\n",
    "#         self.classes = pd.unique(self.pt_classes[class_colname])\n",
    "#         self.labels = self.pt_classes.assign(val = 1).pivot_table(columns = class_colname, index = 'loc_id', values = 'val', fill_value= 0)\n",
    "\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         loc_id = self.labels.index[idx]\n",
    "#         self.last_loc_id = loc_id\n",
    "        \n",
    "#         # select location id\n",
    "#         s2_ts_x = s2_ts[['B8','B4','B3','B2','day']]\n",
    "#         x = torch.tensor(s2_ts_x.to_numpy())\n",
    "        \n",
    "#         # get one-hot encoding for the point as tensor\n",
    "#         y = torch.tensor(self.labels.iloc[idx].to_numpy())\n",
    "        \n",
    "#         return x, y\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.pt_classes.shape[0]\n",
    "\n",
    "\n",
    "# proj_path = \"/Users/gopal/Google Drive/_Research/Research projects/ML/manclassify/app_data/Thailand\"\n",
    "# # date_rangeX = pd.to_datetime(['2019-06-01','2020-05-31'])\n",
    "# s2_dataset = s2Dataset(proj_path = proj_path, class_colname = 'Subclass2019')\n",
    "# x = s2_dataset.__getitem__(10)\n",
    "# sys.getsizeof(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnightly",
   "language": "python",
   "name": "dlnightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

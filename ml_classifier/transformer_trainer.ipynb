{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7217f6c2-4c4c-4e5c-9bb6-8687ed8f5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import re\n",
    "import sys\n",
    "from datetime import timedelta\n",
    "# from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0203fb23-6e71-4789-9584-9573152c660c",
   "metadata": {},
   "source": [
    "### Import classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f95fcad-56ab-43b6-a50d-317152f7e186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>Class</th>\n",
       "      <th>Subclass2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Farm</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Farm</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Farm</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Farm</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Farm</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>Farm</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>Farm</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>Farm</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>Farm</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500</td>\n",
       "      <td>Farm</td>\n",
       "      <td>Crop(Double)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loc_id Class  Subclass2019\n",
       "0         0  Farm    Plantation\n",
       "1         1  Farm  Crop(Single)\n",
       "2         2  Farm  Crop(Single)\n",
       "3         3  Farm  Crop(Single)\n",
       "4         4  Farm    Plantation\n",
       "..      ...   ...           ...\n",
       "496     496  Farm  Crop(Single)\n",
       "497     497  Farm  Crop(Single)\n",
       "498     498  Farm    Plantation\n",
       "499     499  Farm    Plantation\n",
       "500     500  Farm  Crop(Double)\n",
       "\n",
       "[501 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "proj_paths = [\"/Users/gopal/Google Drive/_Research/Research projects/ML/manclassify/app_data/Thailand\",\n",
    "              \"/Users/gopalpenny/Library/CloudStorage/GoogleDrive-gopalpenny@gmail.com/My Drive/_Research/Research projects/ML/manclassify/app_data/Thailand\"]\n",
    "\n",
    "proj_path = [path for path in proj_paths if os.path.exists(path)][0]\n",
    "\n",
    "class_path = os.path.join(proj_path,\"Thailand_classification\")\n",
    "ts_path = os.path.join(proj_path,\"Thailand_download_timeseries\")\n",
    "# pd.read_csv(\"\n",
    "os.listdir(class_path)\n",
    "\n",
    "loc_id = 0\n",
    "\n",
    "s2_csv_name = f\"pt_ts_loc{loc_id}_s2.csv\"\n",
    "s2_csv_name\n",
    "\n",
    "class_colname = 'Subclass2019'\n",
    "\n",
    "proj_normpath = os.path.normpath(proj_path)\n",
    "proj_dirname = proj_normpath.split(os.sep)[-1]\n",
    "proj_name = re.sub(\"_classification$\",\"\",proj_dirname)\n",
    "class_path = os.path.join(proj_path, proj_name + \"_classification\")\n",
    "ts_path = os.path.join(proj_path, proj_name + \"_download_timeseries\")\n",
    "pt_classes = pd.read_csv(os.path.join(class_path, \"location_classification.csv\"))\n",
    "pt_classes = pt_classes[['loc_id', 'Class', class_colname]].dropna()\n",
    "\n",
    "pt_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadc6355-df65-4834-b219-1d3d6ead823f",
   "metadata": {},
   "source": [
    "## Generate the torch tensor dataset\n",
    "\n",
    "### Define function to read timeseries\n",
    "\n",
    "* Read timeseries\n",
    "* Filter timeseries to date range (+/- 60 days)\n",
    "* Remove observations with clouds\n",
    "* Take the mean value for each day (occurs when multiple overpasses happen on the same day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b32be994-4f4d-4666-9e96-9424cc71f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep dataset\n",
    "date_range = pd.to_datetime(['2019-06-01','2020-05-31'])\n",
    "\n",
    "def prep_s2_loc(loc_id, date_range, proj_path):\n",
    "    ts_path = os.path.join(proj_path,\"Thailand_download_timeseries\")\n",
    "    s2_csv_name = f\"pt_ts_loc{loc_id}_s2.csv\"\n",
    "    s2_csv_path = os.path.join(ts_path, s2_csv_name)\n",
    "    s2_ts = pd.read_csv(s2_csv_path)\n",
    "\n",
    "    # extract dates from image ids\n",
    "    s2_ts['datestr'] = [re.sub(\"(^[0-9]+)[a-zA-Z].*\",\"\\\\1\",x) for x in s2_ts.image_id]\n",
    "    s2_ts['date'] = pd.to_datetime(s2_ts.datestr, format = \"%Y%m%d\")\n",
    "\n",
    "    # subset to cloud-free days AND within date_range\n",
    "    s2_ts = s2_ts[(s2_ts.date >= date_range[0] - timedelta(days = 60)) & \n",
    "                  (s2_ts.date <= date_range[1] + timedelta(days = 60)) & \n",
    "                  (s2_ts.cloudmask == 0)]\n",
    "\n",
    "    # calculate day from startday\n",
    "    date_diff = (s2_ts.date - date_range[0])\n",
    "    s2_ts['day'] = [x.days for x in date_diff]\n",
    "    s2_ts['loc_id'] = loc_id\n",
    "\n",
    "    # select only predictor and position columns, return tensor\n",
    "    s2_ts_x = s2_ts[['loc_id','day','B8','B4','B3','B2']]\n",
    "    return s2_ts_x\n",
    "\n",
    "# s2_ts_loc125 = prep_s2_loc(125, date_range, proj_path)\n",
    "# s2_ts_loc125.groupby(['loc_id','day'],as_index = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336b48f-e6ff-468b-95cf-a1396e0e1768",
   "metadata": {},
   "source": [
    "### Get the torch tensor dataset (prep and save OR read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38ac523f-49d7-4427-8d02-85e905ab73f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from ipywidgets import IntProgress\n",
    "# from IPython.display import display\n",
    "\n",
    "if os.path.exists(os.path.join(proj_path, 's2_ts_prepped.pt')):\n",
    "    loc_ts_tor = torch.load(os.path.join(proj_path, 's2_ts_prepped.pt'))\n",
    "    \n",
    "else:\n",
    "    # f = IntProgress(min=0, max=pt_classes.shape[0]) # instantiate the bar\n",
    "    display(f) # display the bar\n",
    "    \n",
    "    s2_ts_list = []\n",
    "    loc_id_list = []\n",
    "    for i in np.arange(pt_classes.shape[0]):\n",
    "        # loc_id = 499\n",
    "        # print(loc_id)\n",
    "        loc_id = pt_classes.loc_id.iloc[i]\n",
    "        # loc_id_list.append(loc_id)\n",
    "        s2_ts_loc = prep_s2_loc(loc_id, date_range, proj_path)\n",
    "        s2_ts_loc = s2_ts_loc.groupby(['loc_id','day'],as_index = False).mean()\n",
    "        s2_ts_tor = torch.tensor(s2_ts_loc.to_numpy())\n",
    "        s2_ts_list.append(s2_ts_tor)\n",
    "        # f.value += 1\n",
    "        \n",
    "    loc_ts_tor = torch.cat(s2_ts_list)\n",
    "\n",
    "    torch.save(loc_ts_tor, os.path.join(proj_path, 's2_ts_prepped.pt'))\n",
    "\n",
    "sys.getsizeof(loc_ts_tor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87657506-61f2-446c-ab16-6d6a4b200b16",
   "metadata": {},
   "source": [
    "### Prep the dataset tensors\n",
    "\n",
    "* Subset to training classes (crops & plantations)\n",
    "* Check max number of rows\n",
    "* Normalize & center\n",
    "* Split loc_id into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1256114-ba88-48eb-b741-08ab43872a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Plantation\n",
       "1      Crop(Single)\n",
       "2      Crop(Single)\n",
       "3      Crop(Single)\n",
       "4        Plantation\n",
       "           ...     \n",
       "496    Crop(Single)\n",
       "497    Crop(Single)\n",
       "498      Plantation\n",
       "499      Plantation\n",
       "500    Crop(Double)\n",
       "Name: class, Length: 501, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a merged class column where \"Other\" is used for nonfarm classes\n",
    "pt_classes['class'] = ['Other' if x!='Farm' else y for x,y in zip(pt_classes['Class'],pt_classes['Subclass2019'])]\n",
    "pt_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7b06a55-3c55-42e7-91fa-6ca3ea412559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All classes\n",
      "                                     loc_id\n",
      "Class     Subclass2019 class               \n",
      "Farm      Crop(Double) Crop(Double)      68\n",
      "          Crop(Single) Crop(Single)     278\n",
      "          Mixed        Mixed              2\n",
      "          Plantation   Plantation       109\n",
      "          Unsure       Unsure             4\n",
      "NonFarm   Forest       Other              3\n",
      "          Golf         Other              1\n",
      "          Mixed        Other              4\n",
      "          Unsure       Other              1\n",
      "          Urban        Other              1\n",
      "Uncertain Mixed        Other              9\n",
      "          Unsure       Other             12\n",
      "Water     Mixed        Other              5\n",
      "          Water        Other              4\n",
      "\n",
      "Training dataset (pt_classes_ag)\n",
      "             class  loc_id\n",
      "0      Plantation       0\n",
      "1    Crop(Single)       1\n",
      "2    Crop(Single)       2\n",
      "3    Crop(Single)       3\n",
      "4      Plantation       4\n",
      "..            ...     ...\n",
      "496  Crop(Single)     496\n",
      "497  Crop(Single)     497\n",
      "498    Plantation     498\n",
      "499    Plantation     499\n",
      "500  Crop(Double)     500\n",
      "\n",
      "[495 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('All classes')\n",
    "print(pt_classes.groupby(['Class','Subclass2019','class']).count())\n",
    "\n",
    "train_classes = ['Crop(Double)','Crop(Single)','Plantation', 'Other']\n",
    "pt_classes_ag = pt_classes[pt_classes['class'].isin(train_classes)][['class','loc_id']]\n",
    "print('\\nTraining dataset (pt_classes_ag)\\n',pt_classes_ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2eb8285a-43e6-452b-b3c8-bc93f837e049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0.,   55., 4320.,  263.,  582.,  304.],\n",
       "        [   0.,  120., 3896.,  472.,  785.,  560.],\n",
       "        [   0.,  145., 3809.,  340.,  623.,  346.],\n",
       "        ...,\n",
       "        [ 500.,  343., 2752., 1473., 1296., 1006.],\n",
       "        [ 500.,  348., 2590., 1245., 1153.,  844.],\n",
       "        [ 500.,  363., 3241., 1605., 1565., 1281.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_ts_tor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d2a727f0-a8c6-415c-b482-e19f70c5f571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of observations for any loc_id\n",
      "     loc_id  num_obs\n",
      "481     481       91\n"
     ]
    }
   ],
   "source": [
    "loc_ts_tor = loc_ts_tor[(loc_ts_tor[:,1] >= 0) & (loc_ts_tor[:,1] <= 365)]\n",
    "\n",
    "row_means= loc_ts_tor.mean(dim = 1)#.shape #.unsqueeze(0).repeat(5,1)\n",
    "loc_ts_tor = loc_ts_tor[~torch.isnan(row_means)]\n",
    "col_means= loc_ts_tor.mean(dim = 0)#.shape #.unsqueeze(0).repeat(5,1)\n",
    "col_std= loc_ts_tor.std(dim = 0)#.shape #.unsqueeze(0).repeat(5,1)\n",
    "col_means[[0,1]] = 0\n",
    "col_std[[0]] = 1\n",
    "col_std[[1]] = 365 # normalize days by 365 -- each year ranges from 0 to 1\n",
    "\n",
    "loc_ts_tor_std = col_std.unsqueeze(0).repeat(loc_ts_tor.shape[0],1)\n",
    "loc_ts_tor_mean = col_means.unsqueeze(0).repeat(loc_ts_tor.shape[0],1)\n",
    "\n",
    "loc_ts_norm = (loc_ts_tor - loc_ts_tor_mean) / loc_ts_tor_std\n",
    "\n",
    "# get max of number of observations per location\n",
    "# idx = np.arange(loc_ts_norm.shape[0])\n",
    "loc_id = np.unique(loc_ts_norm[:,0])\n",
    "num_obs = pd.DataFrame({'loc_id' : np.unique(loc_ts_norm[:,0]).astype('int')})\n",
    "num_obs['num_obs'] = [loc_ts_norm[loc_ts_norm[:,0]==i,:].shape[0] for i in num_obs['loc_id']]\n",
    "print(\"Max number of observations for any loc_id\")\n",
    "print(num_obs.iloc[[num_obs['num_obs'].idxmax()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aa46b110-21e4-4725-8923-8911fd751e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.3288,  1.5379, -1.1047, -0.6794, -0.5649],\n",
       "        [ 0.0000,  0.3973,  1.4139, -1.3247, -1.1319, -1.1984],\n",
       "        [ 0.0000,  0.4521,  0.5745, -1.4665, -1.4839, -1.3997],\n",
       "        [ 0.0000,  0.5205,  1.4938, -1.3297, -1.0649, -0.9705]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_ts_norm[1:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "944c4fc2-d3b8-41fb-8953-ab43c796ef1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (loc_train summary)\n",
      "               loc_id\n",
      "class               \n",
      "Crop(Double)      54\n",
      "Crop(Single)     222\n",
      "Other             32\n",
      "Plantation        87\n",
      "\n",
      "Validate (loc_test summary)\n",
      "               loc_id\n",
      "class               \n",
      "Crop(Double)       7\n",
      "Crop(Single)      28\n",
      "Other              4\n",
      "Plantation        11\n",
      "\n",
      "Testing (loc_test summary)\n",
      "               loc_id\n",
      "class               \n",
      "Crop(Double)       7\n",
      "Crop(Single)      28\n",
      "Other              4\n",
      "Plantation        11\n"
     ]
    }
   ],
   "source": [
    "loc_train = pt_classes_ag.groupby('class', group_keys = False).apply(lambda x: x.sample(frac = 0.8))\n",
    "loc_nontrain = pt_classes_ag[~pt_classes_ag['loc_id'].isin(loc_train.loc_id)]\n",
    "\n",
    "loc_valid = loc_nontrain.groupby('class', group_keys = False).apply(lambda x: x.sample(frac = 0.5))\n",
    "loc_test = loc_nontrain[~loc_nontrain['loc_id'].isin(loc_valid.loc_id)]\n",
    "\n",
    "print('Training (loc_train summary)\\n', loc_train.groupby('class').count())\n",
    "print('\\nValidate (loc_test summary)\\n', loc_valid.groupby('class').count())\n",
    "print('\\nTesting (loc_test summary)\\n', loc_test.groupby('class').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0bdda10b-384d-45fa-96d5-e83ec73a93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>loc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Crop(Double)</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Plantation</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Plantation</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Plantation</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plantation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Plantation</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            class  loc_id\n",
       "128  Crop(Double)     128\n",
       "336  Crop(Double)     336\n",
       "57   Crop(Double)      57\n",
       "106  Crop(Double)     106\n",
       "134  Crop(Double)     134\n",
       "..            ...     ...\n",
       "422    Plantation     422\n",
       "204    Plantation     204\n",
       "446    Plantation     446\n",
       "0      Plantation       0\n",
       "380    Plantation     380\n",
       "\n",
       "[395 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c10ca5-4adb-4726-bc9a-792401378301",
   "metadata": {},
   "source": [
    "## Prepare the S2 dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "848fb5a1-70fc-4de4-8d58-ebaea6adaa25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class s2Dataset(Dataset):\n",
    "    \"\"\"Sentinel 2 dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, x, y, max_obs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (tensor): contains loc_id and predictors as columns, s2 observations as rows\n",
    "            y (tensor): contains loc_id as rows (& first column), class as 1-hot columns\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.max_obs = max_obs\n",
    "        # self.proj_path = proj_path\n",
    "        # proj_normpath = os.path.normpath(proj_path)\n",
    "        # proj_dirname = proj_normpath.split(os.sep)[-1]\n",
    "        # self.proj_name = re.sub(\"_classification$\",\"\",proj_dirname)\n",
    "        # self.class_path = os.path.join(proj_path, self.proj_name + \"_classification\")\n",
    "        # self.ts_path = os.path.join(proj_path, self.proj_name + \"_download_timeseries\")\n",
    "        # self.pt_classes = pd.read_csv(os.path.join(self.class_path,\"location_classification.csv\"))\n",
    "        # self.pt_classes = classes[['loc_id', class_colname]].dropna()\n",
    "        # self.classes = pd.unique(self.pt_classes[class_colname])\n",
    "        # self.labels = self.pt_classes.assign(val = 1).pivot_table(columns = class_colname, index = 'loc_id', values = 'val', fill_value= 0)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get loc_id\n",
    "        loc_id = self.y[idx,0]\n",
    "        self.last_loc_id = loc_id\n",
    "        \n",
    "        # select location id\n",
    "        x_loc = self.x[self.x[:,0]==loc_id]\n",
    "        x_prep = x_loc[:,1:] # remove loc_id column\n",
    "        \n",
    "        # pad zeros to max_obs\n",
    "        n_pad = self.max_obs - x_prep.shape[0]\n",
    "        \n",
    "        x = torch.cat((x_prep, torch.zeros(n_pad, x_prep.shape[1])), dim = 0)\n",
    "        \n",
    "        x = x.float()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # get one-hot encoding for the point as tensor\n",
    "        y = torch.tensor(self.y[idx,1:]).float()\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90680b25-01d0-4c4e-972d-034ea76b5b03",
   "metadata": {
    "tags": []
   },
   "source": [
    "### get training data\n",
    "\n",
    "* `y_train` directly from `loc_train` & pivot\n",
    "* `x_train` from `loc_ts_norm`, subset to `y_train[:,0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "58824da7-827c-430e-9954-0b03a8a80277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train:\n",
      " [[  1   0   1   0   0]\n",
      " [  2   0   1   0   0]\n",
      " [  6   0   0   1   0]\n",
      " ...\n",
      " [498   0   0   0   1]\n",
      " [499   0   0   0   1]\n",
      " [500   1   0   0   0]]\n",
      "y_valid:\n",
      " [[ 0  0  0  0  1]\n",
      " [ 4  0  0  0  1]\n",
      " [ 5  1  0  0  0]\n",
      " [24  0  1  0  0]\n",
      " [26  0  1  0  0]\n",
      " [28  0  1  0  0]\n",
      " [30  0  1  0  0]\n",
      " [62  1  0  0  0]\n",
      " [70  0  1  0  0]\n",
      " [76  0  1  0  0]]\n",
      "y_test:\n",
      " [[  3   0   1   0   0]\n",
      " [ 22   0   0   0   1]\n",
      " [ 91   0   0   0   1]\n",
      " [ 98   0   1   0   0]\n",
      " [109   0   0   0   1]\n",
      " [112   0   1   0   0]\n",
      " [123   1   0   0   0]\n",
      " [128   1   0   0   0]\n",
      " [132   0   0   0   1]\n",
      " [136   0   1   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0000e+00,  1.3699e-02,  2.7465e+00, -1.2764e+00, -1.0649e+00,\n",
       "         -1.2665e+00],\n",
       "        [ 3.0000e+00,  5.4795e-02,  1.2686e+00, -6.6289e-01, -8.2466e-01,\n",
       "         -9.3495e-01],\n",
       "        [ 3.0000e+00,  1.2329e-01,  1.5123e+00, -8.2627e-01, -8.7774e-01,\n",
       "         -1.0830e+00],\n",
       "        ...,\n",
       "        [ 4.8700e+02,  9.0411e-01,  1.1788e+00, -7.4013e-01, -1.7661e-01,\n",
       "         -3.9421e-01],\n",
       "        [ 4.8700e+02,  9.3151e-01,  9.7071e-01, -5.6675e-01, -1.4867e-01,\n",
       "         -3.3698e-01],\n",
       "        [ 4.8700e+02,  9.5890e-01,  1.1180e+00, -1.9275e-01,  4.1651e-01,\n",
       "          1.2581e-01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get y_train values from loc_train\n",
    "y_train_df = (loc_train.assign(val = 1) \\\n",
    "  .pivot_table(columns = 'class', index = ['loc_id'], values = 'val', fill_value= 0) \\\n",
    "  .reset_index(['loc_id']))\n",
    "y_train = y_train_df.to_numpy()\n",
    "print('y_train:\\n',y_train)\n",
    "\n",
    "# get x_train values from loc_ts_norm (based on loc_id)\n",
    "x_train = loc_ts_norm[torch.isin(loc_ts_norm[:,0],torch.tensor(y_train[:,0]).to(torch.float64)),:]\n",
    "\n",
    "# get y_test values from loc_test\n",
    "y_valid_df = (loc_valid.assign(val = 1) \\\n",
    "  .pivot_table(columns = 'class', index = ['loc_id'], values = 'val', fill_value= 0) \\\n",
    "  .reset_index(['loc_id']))\n",
    "y_valid = y_valid_df.to_numpy()\n",
    "print('y_valid:\\n',y_valid[0:10,])\n",
    "\n",
    "# get x_train values from loc_ts_norm (based on loc_id)\n",
    "x_valid = loc_ts_norm[torch.isin(loc_ts_norm[:,0],torch.tensor(y_valid[:,0]).to(torch.float64)),:]\n",
    "\n",
    "# get y_test values from loc_test\n",
    "y_test_df = (loc_test.assign(val = 1) \\\n",
    "  .pivot_table(columns = 'class', index = ['loc_id'], values = 'val', fill_value= 0) \\\n",
    "  .reset_index(['loc_id']))\n",
    "y_test = y_test_df.to_numpy()\n",
    "print('y_test:\\n',y_test[0:10,])\n",
    "\n",
    "# get x_train values from loc_ts_norm (based on loc_id)\n",
    "x_test = loc_ts_norm[torch.isin(loc_ts_norm[:,0],torch.tensor(y_test[:,0]).to(torch.float64)),:]\n",
    "\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631a3d7-b607-474a-a6ef-6a8751ef1aad",
   "metadata": {},
   "source": [
    "### build pytorch dataset: `s2_dateset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "43ba874b-c3df-4eed-9511-8103df128f75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x example, shape: torch.Size([100, 5]) \n",
      "(idx=2) columns: day, B8, B4, B3, B2\n",
      " tensor([[ 1.3699e-02,  3.6786e-01, -7.2624e-01, -4.6153e-01, -6.0636e-01],\n",
      "        [ 5.4795e-02,  2.0966e-01, -6.0287e-01, -5.5650e-01, -5.5012e-01],\n",
      "        [ 1.2329e-01,  1.0605e+00, -9.8465e-01, -6.9896e-01, -9.1719e-01],\n",
      "        [ 3.2877e-01,  5.7878e-01, -8.9462e-01, -6.9058e-01, -5.2052e-01],\n",
      "        [ 3.5616e-01,  5.2035e-01, -5.9120e-01, -2.9393e-01,  4.8882e-04],\n",
      "        [ 3.6986e-01,  1.7973e-01, -1.0480e+00, -1.0537e+00, -1.1481e+00],\n",
      "        [ 3.8356e-01, -1.9794e-02, -8.9962e-01, -1.0537e+00, -9.8824e-01],\n",
      "        [ 3.9726e-01,  1.4838e-01, -6.7622e-01, -6.1237e-01, -4.8795e-01],\n",
      "        [ 4.1096e-01, -2.9343e-01, -7.6292e-01, -9.6154e-01, -8.6391e-01],\n",
      "        [ 4.3836e-01, -4.5020e-01, -6.0620e-01, -5.5371e-01, -2.5705e-01],\n",
      "        [ 4.6575e-01, -5.7419e-01, -6.5622e-01, -8.3583e-01, -6.3005e-01],\n",
      "        [ 4.7945e-01, -4.5020e-01, -5.9287e-01, -8.7774e-01, -9.2015e-01],\n",
      "        [ 4.9315e-01, -4.5590e-01, -4.0781e-01, -6.3751e-01, -5.8268e-01],\n",
      "        [ 5.0685e-01, -4.2740e-01, -3.6947e-01, -6.1237e-01, -6.5077e-01],\n",
      "        [ 5.2055e-01, -4.6303e-01, -3.1945e-01, -5.5929e-01, -4.4059e-01],\n",
      "        [ 5.3425e-01, -3.5044e-01, -2.2276e-01, -3.8052e-01, -3.7842e-01],\n",
      "        [ 5.4795e-01, -5.9699e-01, -2.8111e-01, -5.9002e-01, -5.2052e-01],\n",
      "        [ 5.6164e-01, -4.9011e-01, -4.3605e-03, -1.2633e-01, -3.2074e-02],\n",
      "        [ 5.7534e-01, -5.8417e-01, -1.1029e-02, -2.1292e-01, -1.4312e-02],\n",
      "        [ 6.0274e-01, -5.9557e-01,  5.3990e-02, -3.1907e-01, -1.2680e-01],\n",
      "        [ 6.1644e-01, -5.6564e-01,  1.1401e-01, -2.9672e-01, -2.8666e-01],\n",
      "        [ 6.3014e-01, -5.3001e-01,  2.5572e-01,  2.0050e-01,  5.3925e-01],\n",
      "        [ 6.4384e-01, -6.0555e-01,  2.6739e-01,  2.4515e-02,  1.8995e-01],\n",
      "        [ 6.5753e-01, -4.1172e-01,  3.0740e-01, -2.0733e-01, -2.9114e-02],\n",
      "        [ 6.7123e-01, -4.8155e-01,  3.5575e-01, -6.2527e-04,  3.3052e-02],\n",
      "        [ 7.1233e-01, -3.5756e-01,  4.6078e-01, -7.3252e-02,  9.2257e-02],\n",
      "        [ 7.2603e-01, -2.6778e-01,  5.3080e-01, -6.2079e-02, -4.6875e-02],\n",
      "        [ 7.3973e-01, -3.5756e-01,  5.6081e-01,  1.5860e-01,  4.2381e-01],\n",
      "        [ 7.5342e-01, -3.9034e-01,  7.5920e-01,  7.8710e-01,  1.2468e+00],\n",
      "        [ 7.8082e-01, -3.7039e-01,  4.7245e-01,  6.9208e-02,  2.8171e-01],\n",
      "        [ 8.0822e-01, -6.2122e-01, -1.2440e-01, -3.5259e-01, -2.9850e-01],\n",
      "        [ 8.2192e-01, -4.1457e-01,  6.7327e-02, -1.1799e-02,  2.9059e-01],\n",
      "        [ 8.3562e-01, -3.6469e-01,  2.8572e-01,  4.6866e-01,  8.2936e-01],\n",
      "        [ 8.4932e-01, -5.3999e-01,  1.2068e-01,  2.0050e-01,  6.3990e-01],\n",
      "        [ 8.6301e-01, -9.6612e-01, -2.4110e-01, -2.9951e-01, -9.7200e-02],\n",
      "        [ 8.7671e-01, -6.0697e-01,  2.8406e-01,  5.6642e-01,  1.1461e+00],\n",
      "        [ 8.9041e-01, -9.4189e-01, -1.6607e-01, -4.2521e-01, -2.9258e-01],\n",
      "        [ 9.0411e-01, -6.5258e-01,  1.5645e-02, -1.7661e-01, -5.4317e-03],\n",
      "        [ 9.1781e-01, -9.0769e-01,  2.2237e-01,  4.5190e-01,  9.4185e-01],\n",
      "        [ 9.3151e-01, -6.4403e-01, -1.2440e-01, -1.9616e-01,  1.8250e-02],\n",
      "        [ 9.5890e-01, -4.1172e-01, -3.6113e-01, -3.9169e-01, -2.8666e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "\n",
      "\n",
      "y example (idx=2): crops(double) crops(single) plantation\n",
      " tensor([0., 0., 1., 0.])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "s2_train = s2Dataset(x = x_train, y = y_train, max_obs = 100)\n",
    "s2_valid = s2Dataset(x = x_valid, y = y_valid, max_obs = 100)\n",
    "s2_test = s2Dataset(x = x_test, y = y_test, max_obs = 100)\n",
    "\n",
    "# example item in dataset\n",
    "idx_test = 2\n",
    "x, y = s2_train.__getitem__(idx_test)\n",
    "\n",
    "print(f'x example, shape: {x.shape} \\n(idx={idx_test}) columns: day, B8, B4, B3, B2\\n',x)\n",
    "# print()\n",
    "print(f'\\n\\ny example (idx={idx_test}): crops(double) crops(single) plantation\\n',y)\n",
    "print(y.shape)\n",
    "# sys.getsizeof(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298322ee-b1f3-42a9-a7c9-de79fb131fdc",
   "metadata": {},
   "source": [
    "### generate sampling weights for data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b659b210-d96d-4493-803e-795d6986dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://discuss.pytorch.org/t/how-to-handle-imbalanced-classes/11264/2\n",
    "target_classes = torch.stack([torch.argmax(s2_train.__getitem__(i)[1]) for i in range(s2_train.__len__())])\n",
    "# count of samples in each class\n",
    "class_sample_count = np.array([torch.sum(target_classes == i) for i in torch.unique(target_classes)])\n",
    "\n",
    "# weight for each class (classed must go from 0 to n-1 classes)\n",
    "weight = 1. / class_sample_count\n",
    "sample_weights = np.array([weight[i] for i in target_classes])\n",
    "sampler = WeightedRandomSampler(weights = sample_weights, num_samples = len(sample_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5b0da39c-903e-4f54-9984-837ad79a6878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e1ad4e3d-3d90-45b7-8fcf-180c28fdcc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2_train\n",
    "\n",
    "train_dl = DataLoader(s2_train, batch_size = 20, drop_last = True, sampler = sampler)\n",
    "valid_dl = DataLoader(s2_valid, batch_size = 20, drop_last = False)\n",
    "test_dl = DataLoader(s2_test, batch_size = 20, drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "28c6c16a-7a3b-4167-ae61-22fca489c18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6a2bbd30-e297-47cf-a025-d8983de6c8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i == 1:\n",
      " tensor([ 0.0192,  1.6662, -1.2697, -0.9671, -0.9142])\n",
      "i == 10:\n",
      " tensor([ 0.2192,  0.4505, -1.3748, -1.5146, -1.3583])\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for train, labels in train_dl:\n",
    "    if i == 1:\n",
    "        print(\"i == 1:\\n\",train[1, 1, :])\n",
    "    if i == 10:\n",
    "        print(\"i == 10:\\n\",train[1, 1, :])\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0bb5ebc9-1110-4a56-a1e4-6546698d6905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 100, 5])\n",
      "tensor([[ 0.0137,  0.3679, -0.7262, -0.4615, -0.6064],\n",
      "        [ 0.0548,  0.2097, -0.6029, -0.5565, -0.5501],\n",
      "        [ 0.1233,  1.0605, -0.9846, -0.6990, -0.9172]])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dl))\n",
    "tf_test = train_features[:,:,:]\n",
    "# tf_test\n",
    "# train_labels\n",
    "# tf_test\n",
    "tf_test = tf_test.float()\n",
    "print(tf_test.shape)\n",
    "\n",
    "print(tf_test[0, 0:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "81301d5a-edc6-4b75-a700-6903c00c522f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3318b320-8a22-4274-8b1f-057fdea17c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PositionalEncoding(nn.Module):\n",
    "\n",
    "#     def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "#         super().__init__()\n",
    "#         self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "#         position = torch.arange(max_len).unsqueeze(1)\n",
    "#         div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "#         pe = torch.zeros(max_len, 1, d_model)\n",
    "#         pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "#         pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "#         self.register_buffer('pe', pe)\n",
    "\n",
    "#     def forward(self, x: Tensor) -> Tensor:\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "#         \"\"\"\n",
    "#         x = x + self.pe[:x.size(0)]\n",
    "#         return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "620c3037-9bfe-4bca-aafa-a3f086326271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "nhead = 6 # number of attention heads\n",
    "head_dim = 8 # dimension of each word for each attention head\n",
    "dmodel = nhead * head_dim # embed_dim -- each word (row) is embedded to this dimension then split\n",
    "# across the nhead attention heads\n",
    "\n",
    "data_in = tf_test[:, :, 1:] # select only the data\n",
    "positions = tf_test[:,:,0:1] # split out positional data\n",
    "data_dim = data_in.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9864c574-a237-4233-85ed-f4abda964aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5097])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.tensor([5.2333e-01]))/torch.sum(torch.exp(torch.tensor([-1.3249e-01, 5.2333e-01, -2.9124e-01])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b2cc3947-ba93-4b8c-81a1-75732d2cef06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn, Tensor\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, ntoken: int, dmodel: int, nhead: int, dhid: int, \n",
    "                 nlayers: int, data_dim: int, nclasses: int):\n",
    "        \"\"\"\n",
    "        data_dim: dimension of data (i.e., num of columns) including position as first dimension\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.positional_layer = nn.Linear(1, dmodel)\n",
    "        self.embed_layer = nn.Linear(data_dim - 1, dmodel) # transform data to embed dimension (dmodel)\n",
    "        \n",
    "        # dim_feedforward: https://stackoverflow.com/questions/68087780/pytorch-transformer-argument-dim-feedforward\n",
    "        # shortly: dim_feedforward is a hidden layer between two forward layers at the end of the encoder layer, passed for each word one-by-one\n",
    "        self.encoderlayer = nn.TransformerEncoderLayer(d_model = dmodel, nhead = nhead, dim_feedforward = dhid)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoderlayer, nlayers)\n",
    "        \n",
    "        self.num_params = ntoken * dmodel\n",
    "        \n",
    "        self.class_encoder = nn.Linear(dmodel, nclasses)\n",
    "    \n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \n",
    "        positions = src[:, :, 0:1]\n",
    "        data = src[:, :, 1:]\n",
    "        pe = self.positional_layer(positions)\n",
    "        data_embed = self.embed_layer(data)\n",
    "        data_and_pe = pe + data_embed\n",
    "        encoder_out = self.encoder(data_and_pe)\n",
    "        \n",
    "        maxpool = torch.max(encoder_out,dim = 1)[0]\n",
    "        \n",
    "        # softmax ensures output of model is probability of class membership -- which sum to 1\n",
    "        # BUT this is already done with CrossEntropyLoss so it's not necessary for this loss function\n",
    "        classes = self.class_encoder(maxpool) #, dim = 1\n",
    "        \n",
    "        # classes = nn.functional.softmax(classes, 1) # don't use softmax with cross entropy loss... or do?\n",
    "        # don't: https://stackoverflow.com/questions/55675345/should-i-use-softmax-as-output-when-using-cross-entropy-loss-in-pytorch\n",
    "        # do: Machine Learning with Pytorch and Scikitlearn (p 471: Loss functions for classifiers) -- BUT NOT WITH CROSS ENTROPY LOSS (p478\n",
    "        \n",
    "        return classes\n",
    "\n",
    "        # data_in = tf_test[:, :, 1:] # select only the data\n",
    "        # positions = tf_test[:,:,0:1] # split out positional data\n",
    "        # data_dim = data_in.shape[-1]\n",
    "        \n",
    "        \n",
    "tfnetwork = TransformerClassifier(100, dmodel = 36, nhead = 6, dhid = 100, nlayers = 3, data_dim = 5, nclasses = 4)\n",
    "\n",
    "tfnetwork(tf_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a431a705-bac6-4aef-82b7-584d9564aea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 100, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "TransformerClassifier                         [5, 4]                    12,808\n",
       "â”œâ”€Linear: 1-1                                 [5, 100, 36]              72\n",
       "â”œâ”€Linear: 1-2                                 [5, 100, 36]              180\n",
       "â”œâ”€TransformerEncoder: 1-3                     [5, 100, 36]              --\n",
       "â”‚    â””â”€ModuleList: 2-1                        --                        --\n",
       "â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-1      [5, 100, 36]              12,808\n",
       "â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-2      [5, 100, 36]              12,808\n",
       "â”‚    â”‚    â””â”€TransformerEncoderLayer: 3-3      [5, 100, 36]              12,808\n",
       "â”œâ”€Linear: 1-4                                 [5, 4]                    148\n",
       "===============================================================================================\n",
       "Total params: 51,632\n",
       "Trainable params: 51,632\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.11\n",
       "===============================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 2.78\n",
       "Params size (MB): 0.09\n",
       "Estimated Total Size (MB): 2.89\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "print(tuple(tf_test.shape))\n",
    "summary(tfnetwork, input_size = (5, 100, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "1ca4cfd0-e971-4d55-a945-b18f51565788",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dl))\n",
    "\n",
    "tfnetwork = TransformerClassifier(100, dmodel = 36, nhead = 6, dhid = 100, nlayers = 3, data_dim = 5, nclasses = 4)\n",
    "\n",
    "train_out = tfnetwork(train_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "12c66da9-e674-41a4-b570-d227d8ed1817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9cdb2a18-ffdf-435e-a122-379283314219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(tfnetwork.parameters(), lr = 0.001)\n",
    "\n",
    "print(train_out.shape)\n",
    "\n",
    "def get_num_correct(train_out, train_labels):\n",
    "    pred = torch.argmax(train_out, dim = 1)\n",
    "    actual = torch.argmax(train_labels, dim = 1)\n",
    "    num_correct = torch.sum(pred == actual).item()\n",
    "    # print('type',type(num_correct))\n",
    "    # x = num_correct# item()\n",
    "    # print('num_correct', num_correct.item())\n",
    "    return num_correct\n",
    "\n",
    "\n",
    "num_correct = get_num_correct(train_out, train_labels)\n",
    "num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2b838438-1654-474e-8c9d-6dc618ac8a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 4])\n",
      "<class 'int'>\n",
      "num_correct: 3\n",
      "accuracy: 0.15000000596046448\n",
      "num in training sample: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'accuracy: 0.15000000596046448'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = num_correct / train_labels.size(0)\n",
    "print('num_correct:', num_correct.item())\n",
    "print('accuracy:', accuracy.item())\n",
    "print('num in training sample:', train_labels.size(0))\n",
    "tfnetwork.train()\n",
    "loss = loss_fn(train_out, train_labels)\n",
    "# loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n",
    "# tf_train\n",
    "# tf_test.shape\n",
    "f\"accuracy: {accuracy.item()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4a03101e-4d54-4eb0-9a63-a6b6e2bb4fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_correct(train_out, train_labels).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "18b3e62f-48e8-4e4a-b966-8c072b547129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 1.2917, Accuracy: 0.3139 Val Accuracy: 0.5165\n",
      "Epoch [2/1000], Loss: 1.0431, Accuracy: 0.5190 Val Accuracy: 0.5089\n",
      "Epoch [3/1000], Loss: 0.9446, Accuracy: 0.5570 Val Accuracy: 0.5696\n",
      "Epoch [4/1000], Loss: 0.8469, Accuracy: 0.6101 Val Accuracy: 0.5722\n",
      "Epoch [5/1000], Loss: 0.8658, Accuracy: 0.5924 Val Accuracy: 0.6253\n",
      "Epoch [6/1000], Loss: 0.8070, Accuracy: 0.6430 Val Accuracy: 0.6557\n",
      "Epoch [7/1000], Loss: 0.7509, Accuracy: 0.7089 Val Accuracy: 0.6380\n",
      "Epoch [8/1000], Loss: 0.7394, Accuracy: 0.6684 Val Accuracy: 0.6506\n",
      "Epoch [9/1000], Loss: 0.7102, Accuracy: 0.7038 Val Accuracy: 0.7291\n",
      "Epoch [10/1000], Loss: 0.7344, Accuracy: 0.6886 Val Accuracy: 0.7063\n",
      "Epoch [11/1000], Loss: 0.6577, Accuracy: 0.7367 Val Accuracy: 0.6962\n",
      "Epoch [12/1000], Loss: 0.6434, Accuracy: 0.7468 Val Accuracy: 0.7646\n",
      "Epoch [13/1000], Loss: 0.6492, Accuracy: 0.7089 Val Accuracy: 0.6911\n",
      "Epoch [14/1000], Loss: 0.6310, Accuracy: 0.7063 Val Accuracy: 0.7671\n",
      "Epoch [15/1000], Loss: 0.6281, Accuracy: 0.7165 Val Accuracy: 0.7443\n",
      "Epoch [16/1000], Loss: 0.6002, Accuracy: 0.7367 Val Accuracy: 0.7468\n",
      "Epoch [17/1000], Loss: 0.5929, Accuracy: 0.7316 Val Accuracy: 0.7671\n",
      "Epoch [18/1000], Loss: 0.5171, Accuracy: 0.7747 Val Accuracy: 0.7367\n",
      "Epoch [19/1000], Loss: 0.5808, Accuracy: 0.7266 Val Accuracy: 0.8000\n",
      "Epoch [20/1000], Loss: 0.5364, Accuracy: 0.7797 Val Accuracy: 0.7772\n",
      "Epoch [21/1000], Loss: 0.5251, Accuracy: 0.7772 Val Accuracy: 0.7595\n",
      "Epoch [22/1000], Loss: 0.5071, Accuracy: 0.7848 Val Accuracy: 0.7848\n",
      "Epoch [23/1000], Loss: 0.4943, Accuracy: 0.7772 Val Accuracy: 0.8076\n",
      "Epoch [24/1000], Loss: 0.4813, Accuracy: 0.7924 Val Accuracy: 0.7696\n",
      "Epoch [25/1000], Loss: 0.5027, Accuracy: 0.7646 Val Accuracy: 0.8025\n",
      "Epoch [26/1000], Loss: 0.4879, Accuracy: 0.7899 Val Accuracy: 0.8127\n",
      "Epoch [27/1000], Loss: 0.4797, Accuracy: 0.7949 Val Accuracy: 0.7646\n",
      "Epoch [28/1000], Loss: 0.4650, Accuracy: 0.7823 Val Accuracy: 0.8380\n",
      "Epoch [29/1000], Loss: 0.4469, Accuracy: 0.8051 Val Accuracy: 0.7823\n",
      "Epoch [30/1000], Loss: 0.4113, Accuracy: 0.8152 Val Accuracy: 0.8329\n",
      "Epoch [31/1000], Loss: 0.4353, Accuracy: 0.8228 Val Accuracy: 0.7823\n",
      "Epoch [32/1000], Loss: 0.4852, Accuracy: 0.8203 Val Accuracy: 0.7899\n",
      "Epoch [33/1000], Loss: 0.4060, Accuracy: 0.8253 Val Accuracy: 0.8253\n",
      "Epoch [34/1000], Loss: 0.4393, Accuracy: 0.8051 Val Accuracy: 0.7696\n",
      "Epoch [35/1000], Loss: 0.4440, Accuracy: 0.8127 Val Accuracy: 0.8152\n",
      "Epoch [36/1000], Loss: 0.4368, Accuracy: 0.7924 Val Accuracy: 0.7848\n",
      "Epoch [37/1000], Loss: 0.4010, Accuracy: 0.8228 Val Accuracy: 0.8228\n",
      "Epoch [38/1000], Loss: 0.4870, Accuracy: 0.7797 Val Accuracy: 0.8228\n",
      "Epoch [39/1000], Loss: 0.4584, Accuracy: 0.7620 Val Accuracy: 0.8506\n",
      "Epoch [40/1000], Loss: 0.4113, Accuracy: 0.8051 Val Accuracy: 0.8051\n",
      "Epoch [41/1000], Loss: 0.3501, Accuracy: 0.8430 Val Accuracy: 0.8354\n",
      "Epoch [42/1000], Loss: 0.4244, Accuracy: 0.8127 Val Accuracy: 0.7468\n",
      "Epoch [43/1000], Loss: 0.3815, Accuracy: 0.7975 Val Accuracy: 0.8127\n",
      "Epoch [44/1000], Loss: 0.3208, Accuracy: 0.8456 Val Accuracy: 0.8430\n",
      "Epoch [45/1000], Loss: 0.3750, Accuracy: 0.8127 Val Accuracy: 0.8278\n",
      "Epoch [46/1000], Loss: 0.3046, Accuracy: 0.8608 Val Accuracy: 0.8203\n",
      "Epoch [47/1000], Loss: 0.3105, Accuracy: 0.8608 Val Accuracy: 0.8506\n",
      "Epoch [48/1000], Loss: 0.3131, Accuracy: 0.8354 Val Accuracy: 0.8557\n",
      "Epoch [49/1000], Loss: 0.3718, Accuracy: 0.8506 Val Accuracy: 0.8228\n",
      "Epoch [50/1000], Loss: 0.3083, Accuracy: 0.8405 Val Accuracy: 0.8405\n",
      "Epoch [51/1000], Loss: 0.3056, Accuracy: 0.8582 Val Accuracy: 0.8532\n",
      "Epoch [52/1000], Loss: 0.3091, Accuracy: 0.8481 Val Accuracy: 0.8278\n",
      "Epoch [53/1000], Loss: 0.3120, Accuracy: 0.8405 Val Accuracy: 0.8405\n",
      "Epoch [54/1000], Loss: 0.2824, Accuracy: 0.8582 Val Accuracy: 0.8608\n",
      "Epoch [55/1000], Loss: 0.3145, Accuracy: 0.8481 Val Accuracy: 0.8456\n",
      "Epoch [56/1000], Loss: 0.2960, Accuracy: 0.8759 Val Accuracy: 0.8304\n",
      "Epoch [57/1000], Loss: 0.2862, Accuracy: 0.8481 Val Accuracy: 0.8430\n",
      "Epoch [58/1000], Loss: 0.2965, Accuracy: 0.8506 Val Accuracy: 0.8886\n",
      "Epoch [59/1000], Loss: 0.2698, Accuracy: 0.8532 Val Accuracy: 0.8987\n",
      "Epoch [60/1000], Loss: 0.2903, Accuracy: 0.8684 Val Accuracy: 0.8608\n",
      "Epoch [61/1000], Loss: 0.2693, Accuracy: 0.8734 Val Accuracy: 0.8608\n",
      "Epoch [62/1000], Loss: 0.2502, Accuracy: 0.8684 Val Accuracy: 0.8557\n",
      "Epoch [63/1000], Loss: 0.2886, Accuracy: 0.8532 Val Accuracy: 0.8835\n",
      "Epoch [64/1000], Loss: 0.2805, Accuracy: 0.8557 Val Accuracy: 0.8734\n",
      "Epoch [65/1000], Loss: 0.2377, Accuracy: 0.8861 Val Accuracy: 0.8684\n",
      "Epoch [66/1000], Loss: 0.2545, Accuracy: 0.8658 Val Accuracy: 0.8481\n",
      "Epoch [67/1000], Loss: 0.2583, Accuracy: 0.8633 Val Accuracy: 0.8557\n",
      "Epoch [68/1000], Loss: 0.2720, Accuracy: 0.8557 Val Accuracy: 0.8861\n",
      "Epoch [69/1000], Loss: 0.2305, Accuracy: 0.8785 Val Accuracy: 0.8329\n",
      "Epoch [70/1000], Loss: 0.2515, Accuracy: 0.8658 Val Accuracy: 0.9063\n",
      "Epoch [71/1000], Loss: 0.2593, Accuracy: 0.8861 Val Accuracy: 0.8684\n",
      "Epoch [72/1000], Loss: 0.2488, Accuracy: 0.8658 Val Accuracy: 0.8658\n",
      "Epoch [73/1000], Loss: 0.2393, Accuracy: 0.8709 Val Accuracy: 0.8861\n",
      "Epoch [74/1000], Loss: 0.2547, Accuracy: 0.8582 Val Accuracy: 0.8810\n",
      "Epoch [75/1000], Loss: 0.2254, Accuracy: 0.8835 Val Accuracy: 0.8987\n",
      "Epoch [76/1000], Loss: 0.2099, Accuracy: 0.8861 Val Accuracy: 0.8987\n",
      "Epoch [77/1000], Loss: 0.2148, Accuracy: 0.8962 Val Accuracy: 0.8911\n",
      "Epoch [78/1000], Loss: 0.2137, Accuracy: 0.8911 Val Accuracy: 0.8633\n",
      "Epoch [79/1000], Loss: 0.2381, Accuracy: 0.8759 Val Accuracy: 0.9063\n",
      "Epoch [80/1000], Loss: 0.2270, Accuracy: 0.8861 Val Accuracy: 0.8937\n",
      "Epoch [81/1000], Loss: 0.2580, Accuracy: 0.8734 Val Accuracy: 0.9013\n",
      "Epoch [82/1000], Loss: 0.1885, Accuracy: 0.9013 Val Accuracy: 0.8481\n",
      "Epoch [83/1000], Loss: 0.1775, Accuracy: 0.8911 Val Accuracy: 0.8709\n",
      "Epoch [84/1000], Loss: 0.1943, Accuracy: 0.8987 Val Accuracy: 0.8810\n",
      "Epoch [85/1000], Loss: 0.1861, Accuracy: 0.9139 Val Accuracy: 0.9139\n",
      "Epoch [86/1000], Loss: 0.1886, Accuracy: 0.9089 Val Accuracy: 0.8709\n",
      "Epoch [87/1000], Loss: 0.2034, Accuracy: 0.9063 Val Accuracy: 0.8810\n",
      "Epoch [88/1000], Loss: 0.1867, Accuracy: 0.9063 Val Accuracy: 0.9013\n",
      "Epoch [89/1000], Loss: 0.1785, Accuracy: 0.9038 Val Accuracy: 0.8962\n",
      "Epoch [90/1000], Loss: 0.1790, Accuracy: 0.9139 Val Accuracy: 0.8987\n",
      "Epoch [91/1000], Loss: 0.1899, Accuracy: 0.9063 Val Accuracy: 0.9165\n",
      "Epoch [92/1000], Loss: 0.1604, Accuracy: 0.9165 Val Accuracy: 0.9114\n",
      "Epoch [93/1000], Loss: 0.1696, Accuracy: 0.9114 Val Accuracy: 0.8835\n",
      "Epoch [94/1000], Loss: 0.1338, Accuracy: 0.9165 Val Accuracy: 0.9190\n",
      "Epoch [95/1000], Loss: 0.1539, Accuracy: 0.9089 Val Accuracy: 0.9139\n",
      "Epoch [96/1000], Loss: 0.1463, Accuracy: 0.9190 Val Accuracy: 0.9190\n",
      "Epoch [97/1000], Loss: 0.1466, Accuracy: 0.9215 Val Accuracy: 0.9089\n",
      "Epoch [98/1000], Loss: 0.1445, Accuracy: 0.9342 Val Accuracy: 0.9190\n",
      "Epoch [99/1000], Loss: 0.1658, Accuracy: 0.9063 Val Accuracy: 0.9266\n",
      "Epoch [100/1000], Loss: 0.1881, Accuracy: 0.8810 Val Accuracy: 0.8911\n",
      "Epoch [101/1000], Loss: 0.1510, Accuracy: 0.9089 Val Accuracy: 0.9013\n",
      "Epoch [102/1000], Loss: 0.1429, Accuracy: 0.9241 Val Accuracy: 0.8861\n",
      "Epoch [103/1000], Loss: 0.1799, Accuracy: 0.9215 Val Accuracy: 0.9165\n",
      "Epoch [104/1000], Loss: 0.1691, Accuracy: 0.9038 Val Accuracy: 0.9266\n",
      "Epoch [105/1000], Loss: 0.1579, Accuracy: 0.9063 Val Accuracy: 0.8886\n",
      "Epoch [106/1000], Loss: 0.1439, Accuracy: 0.9114 Val Accuracy: 0.9215\n",
      "Epoch [107/1000], Loss: 0.1698, Accuracy: 0.9063 Val Accuracy: 0.8987\n",
      "Epoch [108/1000], Loss: 0.1874, Accuracy: 0.8962 Val Accuracy: 0.9165\n",
      "Epoch [109/1000], Loss: 0.1619, Accuracy: 0.9165 Val Accuracy: 0.8962\n",
      "Epoch [110/1000], Loss: 0.1825, Accuracy: 0.8911 Val Accuracy: 0.8835\n",
      "Epoch [111/1000], Loss: 0.1726, Accuracy: 0.9089 Val Accuracy: 0.9190\n",
      "Epoch [112/1000], Loss: 0.1519, Accuracy: 0.9038 Val Accuracy: 0.9165\n",
      "Epoch [113/1000], Loss: 0.1262, Accuracy: 0.9316 Val Accuracy: 0.9342\n",
      "Epoch [114/1000], Loss: 0.1628, Accuracy: 0.9089 Val Accuracy: 0.9241\n",
      "Epoch [115/1000], Loss: 0.1594, Accuracy: 0.9241 Val Accuracy: 0.9190\n",
      "Epoch [116/1000], Loss: 0.1261, Accuracy: 0.9367 Val Accuracy: 0.9291\n",
      "Epoch [117/1000], Loss: 0.1483, Accuracy: 0.9114 Val Accuracy: 0.8987\n",
      "Epoch [118/1000], Loss: 0.1131, Accuracy: 0.9342 Val Accuracy: 0.9190\n",
      "Epoch [119/1000], Loss: 0.1332, Accuracy: 0.9215 Val Accuracy: 0.8886\n",
      "Epoch [120/1000], Loss: 0.1420, Accuracy: 0.9114 Val Accuracy: 0.9215\n",
      "Epoch [121/1000], Loss: 0.1626, Accuracy: 0.9165 Val Accuracy: 0.9114\n",
      "Epoch [122/1000], Loss: 0.1474, Accuracy: 0.9114 Val Accuracy: 0.9316\n",
      "Epoch [123/1000], Loss: 0.1344, Accuracy: 0.9215 Val Accuracy: 0.9139\n",
      "Epoch [124/1000], Loss: 0.1296, Accuracy: 0.9190 Val Accuracy: 0.9291\n",
      "Epoch [125/1000], Loss: 0.1190, Accuracy: 0.9266 Val Accuracy: 0.9418\n",
      "Epoch [126/1000], Loss: 0.1110, Accuracy: 0.9367 Val Accuracy: 0.9089\n",
      "Epoch [127/1000], Loss: 0.1145, Accuracy: 0.9266 Val Accuracy: 0.9342\n",
      "Epoch [128/1000], Loss: 0.1269, Accuracy: 0.9215 Val Accuracy: 0.9241\n",
      "Epoch [129/1000], Loss: 0.0946, Accuracy: 0.9418 Val Accuracy: 0.9291\n",
      "Epoch [130/1000], Loss: 0.1346, Accuracy: 0.9215 Val Accuracy: 0.8886\n",
      "Epoch [131/1000], Loss: 0.1156, Accuracy: 0.9367 Val Accuracy: 0.9089\n",
      "Epoch [132/1000], Loss: 0.1455, Accuracy: 0.9063 Val Accuracy: 0.9266\n",
      "Epoch [133/1000], Loss: 0.1167, Accuracy: 0.9190 Val Accuracy: 0.9241\n",
      "Epoch [134/1000], Loss: 0.1059, Accuracy: 0.9392 Val Accuracy: 0.9342\n",
      "Epoch [135/1000], Loss: 0.0940, Accuracy: 0.9468 Val Accuracy: 0.9266\n",
      "Epoch [136/1000], Loss: 0.1014, Accuracy: 0.9291 Val Accuracy: 0.9418\n",
      "Epoch [137/1000], Loss: 0.0896, Accuracy: 0.9418 Val Accuracy: 0.9342\n",
      "Epoch [138/1000], Loss: 0.1082, Accuracy: 0.9316 Val Accuracy: 0.9165\n",
      "Epoch [139/1000], Loss: 0.1228, Accuracy: 0.9316 Val Accuracy: 0.9342\n",
      "Epoch [140/1000], Loss: 0.0939, Accuracy: 0.9367 Val Accuracy: 0.9418\n",
      "Epoch [141/1000], Loss: 0.1146, Accuracy: 0.9266 Val Accuracy: 0.9443\n",
      "Epoch [142/1000], Loss: 0.1172, Accuracy: 0.9215 Val Accuracy: 0.9342\n",
      "Epoch [143/1000], Loss: 0.1340, Accuracy: 0.9139 Val Accuracy: 0.9443\n",
      "Epoch [144/1000], Loss: 0.1140, Accuracy: 0.9190 Val Accuracy: 0.9418\n",
      "Epoch [145/1000], Loss: 0.0889, Accuracy: 0.9367 Val Accuracy: 0.9367\n",
      "Epoch [146/1000], Loss: 0.0804, Accuracy: 0.9418 Val Accuracy: 0.9266\n",
      "Epoch [147/1000], Loss: 0.0993, Accuracy: 0.9418 Val Accuracy: 0.9468\n",
      "Epoch [148/1000], Loss: 0.0926, Accuracy: 0.9392 Val Accuracy: 0.9367\n",
      "Epoch [149/1000], Loss: 0.0793, Accuracy: 0.9468 Val Accuracy: 0.9494\n",
      "Epoch [150/1000], Loss: 0.0618, Accuracy: 0.9494 Val Accuracy: 0.9165\n",
      "Epoch [151/1000], Loss: 0.0754, Accuracy: 0.9468 Val Accuracy: 0.9342\n",
      "Epoch [152/1000], Loss: 0.0733, Accuracy: 0.9519 Val Accuracy: 0.9342\n",
      "Epoch [153/1000], Loss: 0.0788, Accuracy: 0.9418 Val Accuracy: 0.9392\n",
      "Epoch [154/1000], Loss: 0.0715, Accuracy: 0.9443 Val Accuracy: 0.9392\n",
      "Epoch [155/1000], Loss: 0.0747, Accuracy: 0.9418 Val Accuracy: 0.9342\n",
      "Epoch [156/1000], Loss: 0.0788, Accuracy: 0.9443 Val Accuracy: 0.9443\n",
      "Epoch [157/1000], Loss: 0.0881, Accuracy: 0.9418 Val Accuracy: 0.9443\n",
      "Epoch [158/1000], Loss: 0.0876, Accuracy: 0.9392 Val Accuracy: 0.9291\n",
      "Epoch [159/1000], Loss: 0.1077, Accuracy: 0.9291 Val Accuracy: 0.9443\n",
      "Epoch [160/1000], Loss: 0.0755, Accuracy: 0.9392 Val Accuracy: 0.9443\n",
      "Epoch [161/1000], Loss: 0.0677, Accuracy: 0.9392 Val Accuracy: 0.9418\n",
      "Epoch [162/1000], Loss: 0.0980, Accuracy: 0.9342 Val Accuracy: 0.9342\n",
      "Epoch [163/1000], Loss: 0.1248, Accuracy: 0.9190 Val Accuracy: 0.9241\n",
      "Epoch [164/1000], Loss: 0.0858, Accuracy: 0.9418 Val Accuracy: 0.9494\n",
      "Epoch [165/1000], Loss: 0.0798, Accuracy: 0.9519 Val Accuracy: 0.9468\n",
      "Epoch [166/1000], Loss: 0.0789, Accuracy: 0.9392 Val Accuracy: 0.9468\n",
      "Epoch [167/1000], Loss: 0.0589, Accuracy: 0.9519 Val Accuracy: 0.9367\n",
      "Epoch [168/1000], Loss: 0.0671, Accuracy: 0.9468 Val Accuracy: 0.9468\n",
      "Epoch [169/1000], Loss: 0.0668, Accuracy: 0.9468 Val Accuracy: 0.9342\n",
      "Epoch [170/1000], Loss: 0.0950, Accuracy: 0.9392 Val Accuracy: 0.9342\n",
      "Epoch [171/1000], Loss: 0.0735, Accuracy: 0.9367 Val Accuracy: 0.9392\n",
      "Epoch [172/1000], Loss: 0.0888, Accuracy: 0.9392 Val Accuracy: 0.9443\n",
      "Epoch [173/1000], Loss: 0.0870, Accuracy: 0.9342 Val Accuracy: 0.9342\n",
      "Epoch [174/1000], Loss: 0.0554, Accuracy: 0.9570 Val Accuracy: 0.9494\n",
      "Epoch [175/1000], Loss: 0.0763, Accuracy: 0.9494 Val Accuracy: 0.9367\n",
      "Epoch [176/1000], Loss: 0.0852, Accuracy: 0.9392 Val Accuracy: 0.9316\n",
      "Epoch [177/1000], Loss: 0.0729, Accuracy: 0.9443 Val Accuracy: 0.9494\n",
      "Epoch [178/1000], Loss: 0.0899, Accuracy: 0.9316 Val Accuracy: 0.9165\n",
      "Epoch [179/1000], Loss: 0.0785, Accuracy: 0.9392 Val Accuracy: 0.9494\n",
      "Epoch [180/1000], Loss: 0.0846, Accuracy: 0.9392 Val Accuracy: 0.9342\n",
      "Epoch [181/1000], Loss: 0.0777, Accuracy: 0.9342 Val Accuracy: 0.9291\n",
      "Epoch [182/1000], Loss: 0.0908, Accuracy: 0.9367 Val Accuracy: 0.9241\n",
      "Epoch [183/1000], Loss: 0.0634, Accuracy: 0.9468 Val Accuracy: 0.9519\n",
      "Epoch [184/1000], Loss: 0.0545, Accuracy: 0.9468 Val Accuracy: 0.9570\n",
      "Epoch [185/1000], Loss: 0.0644, Accuracy: 0.9468 Val Accuracy: 0.9418\n",
      "Epoch [186/1000], Loss: 0.0626, Accuracy: 0.9443 Val Accuracy: 0.9443\n",
      "Epoch [187/1000], Loss: 0.0793, Accuracy: 0.9443 Val Accuracy: 0.9392\n",
      "Epoch [188/1000], Loss: 0.0425, Accuracy: 0.9595 Val Accuracy: 0.9468\n",
      "Epoch [189/1000], Loss: 0.0621, Accuracy: 0.9443 Val Accuracy: 0.9519\n",
      "Epoch [190/1000], Loss: 0.0532, Accuracy: 0.9544 Val Accuracy: 0.9443\n",
      "Epoch [191/1000], Loss: 0.0666, Accuracy: 0.9443 Val Accuracy: 0.9418\n",
      "Epoch [192/1000], Loss: 0.0849, Accuracy: 0.9367 Val Accuracy: 0.9468\n",
      "Epoch [193/1000], Loss: 0.0753, Accuracy: 0.9392 Val Accuracy: 0.9443\n",
      "Epoch [194/1000], Loss: 0.0723, Accuracy: 0.9418 Val Accuracy: 0.9494\n",
      "Epoch [195/1000], Loss: 0.0505, Accuracy: 0.9494 Val Accuracy: 0.9544\n",
      "Epoch [196/1000], Loss: 0.0736, Accuracy: 0.9443 Val Accuracy: 0.9392\n",
      "Epoch [197/1000], Loss: 0.0687, Accuracy: 0.9392 Val Accuracy: 0.9190\n",
      "Epoch [198/1000], Loss: 0.0866, Accuracy: 0.9342 Val Accuracy: 0.9494\n",
      "Epoch [199/1000], Loss: 0.0585, Accuracy: 0.9468 Val Accuracy: 0.9443\n",
      "Epoch [200/1000], Loss: 0.0601, Accuracy: 0.9392 Val Accuracy: 0.9418\n",
      "Epoch [201/1000], Loss: 0.0549, Accuracy: 0.9494 Val Accuracy: 0.9620\n",
      "Epoch [202/1000], Loss: 0.0476, Accuracy: 0.9544 Val Accuracy: 0.9494\n",
      "Epoch [203/1000], Loss: 0.0582, Accuracy: 0.9443 Val Accuracy: 0.9519\n",
      "Epoch [204/1000], Loss: 0.0516, Accuracy: 0.9519 Val Accuracy: 0.9418\n",
      "Epoch [205/1000], Loss: 0.0736, Accuracy: 0.9392 Val Accuracy: 0.9519\n",
      "Epoch [206/1000], Loss: 0.0818, Accuracy: 0.9291 Val Accuracy: 0.9519\n",
      "Epoch [207/1000], Loss: 0.0667, Accuracy: 0.9519 Val Accuracy: 0.9494\n",
      "Epoch [208/1000], Loss: 0.0469, Accuracy: 0.9544 Val Accuracy: 0.9519\n",
      "Epoch [209/1000], Loss: 0.0415, Accuracy: 0.9570 Val Accuracy: 0.9519\n",
      "Epoch [210/1000], Loss: 0.0491, Accuracy: 0.9468 Val Accuracy: 0.9494\n",
      "Epoch [211/1000], Loss: 0.0572, Accuracy: 0.9494 Val Accuracy: 0.9494\n",
      "Epoch [212/1000], Loss: 0.0389, Accuracy: 0.9595 Val Accuracy: 0.9494\n",
      "Epoch [213/1000], Loss: 0.0300, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [214/1000], Loss: 0.0276, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [215/1000], Loss: 0.0352, Accuracy: 0.9544 Val Accuracy: 0.9519\n",
      "Epoch [216/1000], Loss: 0.0502, Accuracy: 0.9418 Val Accuracy: 0.9544\n",
      "Epoch [217/1000], Loss: 0.0282, Accuracy: 0.9570 Val Accuracy: 0.9494\n",
      "Epoch [218/1000], Loss: 0.0410, Accuracy: 0.9494 Val Accuracy: 0.9544\n",
      "Epoch [219/1000], Loss: 0.0547, Accuracy: 0.9468 Val Accuracy: 0.9494\n",
      "Epoch [220/1000], Loss: 0.0527, Accuracy: 0.9494 Val Accuracy: 0.9494\n",
      "Epoch [221/1000], Loss: 0.0360, Accuracy: 0.9570 Val Accuracy: 0.9494\n",
      "Epoch [222/1000], Loss: 0.0352, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [223/1000], Loss: 0.0426, Accuracy: 0.9519 Val Accuracy: 0.9494\n",
      "Epoch [224/1000], Loss: 0.0524, Accuracy: 0.9519 Val Accuracy: 0.9468\n",
      "Epoch [225/1000], Loss: 0.0451, Accuracy: 0.9544 Val Accuracy: 0.9443\n",
      "Epoch [226/1000], Loss: 0.0438, Accuracy: 0.9519 Val Accuracy: 0.9595\n",
      "Epoch [227/1000], Loss: 0.0508, Accuracy: 0.9468 Val Accuracy: 0.9544\n",
      "Epoch [228/1000], Loss: 0.0464, Accuracy: 0.9494 Val Accuracy: 0.9266\n",
      "Epoch [229/1000], Loss: 0.0517, Accuracy: 0.9468 Val Accuracy: 0.9443\n",
      "Epoch [230/1000], Loss: 0.0521, Accuracy: 0.9392 Val Accuracy: 0.9494\n",
      "Epoch [231/1000], Loss: 0.0442, Accuracy: 0.9519 Val Accuracy: 0.9544\n",
      "Epoch [232/1000], Loss: 0.0462, Accuracy: 0.9519 Val Accuracy: 0.9519\n",
      "Epoch [233/1000], Loss: 0.0429, Accuracy: 0.9519 Val Accuracy: 0.9595\n",
      "Epoch [234/1000], Loss: 0.0460, Accuracy: 0.9494 Val Accuracy: 0.9519\n",
      "Epoch [235/1000], Loss: 0.0430, Accuracy: 0.9468 Val Accuracy: 0.9443\n",
      "Epoch [236/1000], Loss: 0.0428, Accuracy: 0.9443 Val Accuracy: 0.9570\n",
      "Epoch [237/1000], Loss: 0.0431, Accuracy: 0.9519 Val Accuracy: 0.9570\n",
      "Epoch [238/1000], Loss: 0.0274, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [239/1000], Loss: 0.0328, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [240/1000], Loss: 0.0329, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [241/1000], Loss: 0.0246, Accuracy: 0.9570 Val Accuracy: 0.9418\n",
      "Epoch [242/1000], Loss: 0.0499, Accuracy: 0.9570 Val Accuracy: 0.9494\n",
      "Epoch [243/1000], Loss: 0.0556, Accuracy: 0.9443 Val Accuracy: 0.9519\n",
      "Epoch [244/1000], Loss: 0.0304, Accuracy: 0.9544 Val Accuracy: 0.9494\n",
      "Epoch [245/1000], Loss: 0.0292, Accuracy: 0.9544 Val Accuracy: 0.9544\n",
      "Epoch [246/1000], Loss: 0.0234, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [247/1000], Loss: 0.0384, Accuracy: 0.9544 Val Accuracy: 0.9494\n",
      "Epoch [248/1000], Loss: 0.0329, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [249/1000], Loss: 0.0376, Accuracy: 0.9494 Val Accuracy: 0.9468\n",
      "Epoch [250/1000], Loss: 0.0667, Accuracy: 0.9494 Val Accuracy: 0.9443\n",
      "Epoch [251/1000], Loss: 0.0754, Accuracy: 0.9418 Val Accuracy: 0.9418\n",
      "Epoch [252/1000], Loss: 0.0526, Accuracy: 0.9468 Val Accuracy: 0.9468\n",
      "Epoch [253/1000], Loss: 0.0375, Accuracy: 0.9544 Val Accuracy: 0.9418\n",
      "Epoch [254/1000], Loss: 0.0548, Accuracy: 0.9468 Val Accuracy: 0.9544\n",
      "Epoch [255/1000], Loss: 0.0315, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [256/1000], Loss: 0.0336, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [257/1000], Loss: 0.0228, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [258/1000], Loss: 0.0268, Accuracy: 0.9595 Val Accuracy: 0.9519\n",
      "Epoch [259/1000], Loss: 0.0274, Accuracy: 0.9544 Val Accuracy: 0.9620\n",
      "Epoch [260/1000], Loss: 0.0285, Accuracy: 0.9595 Val Accuracy: 0.9494\n",
      "Epoch [261/1000], Loss: 0.0269, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [262/1000], Loss: 0.0237, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [263/1000], Loss: 0.0724, Accuracy: 0.9367 Val Accuracy: 0.9266\n",
      "Epoch [264/1000], Loss: 0.0591, Accuracy: 0.9367 Val Accuracy: 0.9392\n",
      "Epoch [265/1000], Loss: 0.0463, Accuracy: 0.9468 Val Accuracy: 0.9570\n",
      "Epoch [266/1000], Loss: 0.0320, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [267/1000], Loss: 0.0251, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [268/1000], Loss: 0.0322, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [269/1000], Loss: 0.0351, Accuracy: 0.9544 Val Accuracy: 0.9519\n",
      "Epoch [270/1000], Loss: 0.0473, Accuracy: 0.9519 Val Accuracy: 0.9570\n",
      "Epoch [271/1000], Loss: 0.0296, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [272/1000], Loss: 0.0426, Accuracy: 0.9443 Val Accuracy: 0.9519\n",
      "Epoch [273/1000], Loss: 0.0530, Accuracy: 0.9468 Val Accuracy: 0.9443\n",
      "Epoch [274/1000], Loss: 0.0457, Accuracy: 0.9494 Val Accuracy: 0.9519\n",
      "Epoch [275/1000], Loss: 0.0402, Accuracy: 0.9494 Val Accuracy: 0.9544\n",
      "Epoch [276/1000], Loss: 0.0281, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [277/1000], Loss: 0.0425, Accuracy: 0.9468 Val Accuracy: 0.9468\n",
      "Epoch [278/1000], Loss: 0.0402, Accuracy: 0.9494 Val Accuracy: 0.9392\n",
      "Epoch [279/1000], Loss: 0.0673, Accuracy: 0.9367 Val Accuracy: 0.9544\n",
      "Epoch [280/1000], Loss: 0.0362, Accuracy: 0.9519 Val Accuracy: 0.9494\n",
      "Epoch [281/1000], Loss: 0.0335, Accuracy: 0.9544 Val Accuracy: 0.9418\n",
      "Epoch [282/1000], Loss: 0.0415, Accuracy: 0.9519 Val Accuracy: 0.9519\n",
      "Epoch [283/1000], Loss: 0.0588, Accuracy: 0.9418 Val Accuracy: 0.9494\n",
      "Epoch [284/1000], Loss: 0.0431, Accuracy: 0.9494 Val Accuracy: 0.9443\n",
      "Epoch [285/1000], Loss: 0.0563, Accuracy: 0.9443 Val Accuracy: 0.9494\n",
      "Epoch [286/1000], Loss: 0.0283, Accuracy: 0.9595 Val Accuracy: 0.9468\n",
      "Epoch [287/1000], Loss: 0.0330, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [288/1000], Loss: 0.0178, Accuracy: 0.9620 Val Accuracy: 0.9494\n",
      "Epoch [289/1000], Loss: 0.0285, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [290/1000], Loss: 0.0214, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [291/1000], Loss: 0.0169, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [292/1000], Loss: 0.0221, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [293/1000], Loss: 0.0214, Accuracy: 0.9570 Val Accuracy: 0.9468\n",
      "Epoch [294/1000], Loss: 0.0291, Accuracy: 0.9570 Val Accuracy: 0.9494\n",
      "Epoch [295/1000], Loss: 0.0400, Accuracy: 0.9443 Val Accuracy: 0.9468\n",
      "Epoch [296/1000], Loss: 0.0289, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [297/1000], Loss: 0.0297, Accuracy: 0.9570 Val Accuracy: 0.9443\n",
      "Epoch [298/1000], Loss: 0.0265, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [299/1000], Loss: 0.0167, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [300/1000], Loss: 0.0197, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [301/1000], Loss: 0.0173, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [302/1000], Loss: 0.0159, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [303/1000], Loss: 0.0233, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [304/1000], Loss: 0.0452, Accuracy: 0.9544 Val Accuracy: 0.9519\n",
      "Epoch [305/1000], Loss: 0.0210, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [306/1000], Loss: 0.0283, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [307/1000], Loss: 0.0175, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [308/1000], Loss: 0.0145, Accuracy: 0.9620 Val Accuracy: 0.9544\n",
      "Epoch [309/1000], Loss: 0.0198, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [310/1000], Loss: 0.0196, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [311/1000], Loss: 0.0239, Accuracy: 0.9519 Val Accuracy: 0.9544\n",
      "Epoch [312/1000], Loss: 0.0252, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [313/1000], Loss: 0.0216, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [314/1000], Loss: 0.0352, Accuracy: 0.9519 Val Accuracy: 0.9570\n",
      "Epoch [315/1000], Loss: 0.0173, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [316/1000], Loss: 0.0260, Accuracy: 0.9544 Val Accuracy: 0.9519\n",
      "Epoch [317/1000], Loss: 0.0360, Accuracy: 0.9544 Val Accuracy: 0.9443\n",
      "Epoch [318/1000], Loss: 0.0416, Accuracy: 0.9468 Val Accuracy: 0.9443\n",
      "Epoch [319/1000], Loss: 0.0776, Accuracy: 0.9392 Val Accuracy: 0.9291\n",
      "Epoch [320/1000], Loss: 0.0751, Accuracy: 0.9392 Val Accuracy: 0.9367\n",
      "Epoch [321/1000], Loss: 0.1059, Accuracy: 0.9190 Val Accuracy: 0.9316\n",
      "Epoch [322/1000], Loss: 0.0938, Accuracy: 0.9266 Val Accuracy: 0.9165\n",
      "Epoch [323/1000], Loss: 0.1055, Accuracy: 0.9266 Val Accuracy: 0.9494\n",
      "Epoch [324/1000], Loss: 0.0565, Accuracy: 0.9392 Val Accuracy: 0.9494\n",
      "Epoch [325/1000], Loss: 0.0476, Accuracy: 0.9443 Val Accuracy: 0.9418\n",
      "Epoch [326/1000], Loss: 0.0502, Accuracy: 0.9468 Val Accuracy: 0.9468\n",
      "Epoch [327/1000], Loss: 0.0621, Accuracy: 0.9392 Val Accuracy: 0.9620\n",
      "Epoch [328/1000], Loss: 0.0504, Accuracy: 0.9443 Val Accuracy: 0.9367\n",
      "Epoch [329/1000], Loss: 0.0424, Accuracy: 0.9494 Val Accuracy: 0.9392\n",
      "Epoch [330/1000], Loss: 0.0323, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [331/1000], Loss: 0.0234, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [332/1000], Loss: 0.0261, Accuracy: 0.9570 Val Accuracy: 0.9443\n",
      "Epoch [333/1000], Loss: 0.0234, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [334/1000], Loss: 0.0132, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [335/1000], Loss: 0.0146, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [336/1000], Loss: 0.0178, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [337/1000], Loss: 0.0133, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [338/1000], Loss: 0.0102, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [339/1000], Loss: 0.0202, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [340/1000], Loss: 0.0303, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [341/1000], Loss: 0.0219, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [342/1000], Loss: 0.0162, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [343/1000], Loss: 0.0258, Accuracy: 0.9544 Val Accuracy: 0.9620\n",
      "Epoch [344/1000], Loss: 0.0161, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [345/1000], Loss: 0.0222, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [346/1000], Loss: 0.0132, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [347/1000], Loss: 0.0239, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [348/1000], Loss: 0.0247, Accuracy: 0.9544 Val Accuracy: 0.9544\n",
      "Epoch [349/1000], Loss: 0.0137, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [350/1000], Loss: 0.0228, Accuracy: 0.9595 Val Accuracy: 0.9519\n",
      "Epoch [351/1000], Loss: 0.0174, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [352/1000], Loss: 0.0166, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [353/1000], Loss: 0.0234, Accuracy: 0.9494 Val Accuracy: 0.9544\n",
      "Epoch [354/1000], Loss: 0.0163, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [355/1000], Loss: 0.0278, Accuracy: 0.9519 Val Accuracy: 0.9544\n",
      "Epoch [356/1000], Loss: 0.0474, Accuracy: 0.9468 Val Accuracy: 0.9544\n",
      "Epoch [357/1000], Loss: 0.0393, Accuracy: 0.9519 Val Accuracy: 0.9468\n",
      "Epoch [358/1000], Loss: 0.0202, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [359/1000], Loss: 0.0184, Accuracy: 0.9544 Val Accuracy: 0.9544\n",
      "Epoch [360/1000], Loss: 0.0185, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [361/1000], Loss: 0.0368, Accuracy: 0.9544 Val Accuracy: 0.9418\n",
      "Epoch [362/1000], Loss: 0.0405, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [363/1000], Loss: 0.0235, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [364/1000], Loss: 0.0280, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [365/1000], Loss: 0.0196, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [366/1000], Loss: 0.0152, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [367/1000], Loss: 0.0187, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [368/1000], Loss: 0.0262, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [369/1000], Loss: 0.0182, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [370/1000], Loss: 0.0204, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [371/1000], Loss: 0.0164, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [372/1000], Loss: 0.0136, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [373/1000], Loss: 0.0136, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [374/1000], Loss: 0.0117, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [375/1000], Loss: 0.0079, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [376/1000], Loss: 0.0134, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [377/1000], Loss: 0.0066, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [378/1000], Loss: 0.0349, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [379/1000], Loss: 0.0305, Accuracy: 0.9468 Val Accuracy: 0.9494\n",
      "Epoch [380/1000], Loss: 0.0506, Accuracy: 0.9367 Val Accuracy: 0.9519\n",
      "Epoch [381/1000], Loss: 0.0873, Accuracy: 0.9266 Val Accuracy: 0.9316\n",
      "Epoch [382/1000], Loss: 0.0509, Accuracy: 0.9392 Val Accuracy: 0.9595\n",
      "Epoch [383/1000], Loss: 0.0473, Accuracy: 0.9468 Val Accuracy: 0.9595\n",
      "Epoch [384/1000], Loss: 0.0355, Accuracy: 0.9494 Val Accuracy: 0.9570\n",
      "Epoch [385/1000], Loss: 0.0565, Accuracy: 0.9443 Val Accuracy: 0.9367\n",
      "Epoch [386/1000], Loss: 0.0424, Accuracy: 0.9494 Val Accuracy: 0.9342\n",
      "Epoch [387/1000], Loss: 0.0403, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [388/1000], Loss: 0.0347, Accuracy: 0.9443 Val Accuracy: 0.9570\n",
      "Epoch [389/1000], Loss: 0.0180, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [390/1000], Loss: 0.0111, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [391/1000], Loss: 0.0215, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [392/1000], Loss: 0.0144, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [393/1000], Loss: 0.0102, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [394/1000], Loss: 0.0087, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [395/1000], Loss: 0.0166, Accuracy: 0.9544 Val Accuracy: 0.9544\n",
      "Epoch [396/1000], Loss: 0.0113, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [397/1000], Loss: 0.0109, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [398/1000], Loss: 0.0149, Accuracy: 0.9570 Val Accuracy: 0.9418\n",
      "Epoch [399/1000], Loss: 0.0137, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [400/1000], Loss: 0.0106, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [401/1000], Loss: 0.0110, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [402/1000], Loss: 0.0117, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [403/1000], Loss: 0.0246, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [404/1000], Loss: 0.0175, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [405/1000], Loss: 0.0155, Accuracy: 0.9595 Val Accuracy: 0.9443\n",
      "Epoch [406/1000], Loss: 0.0729, Accuracy: 0.9392 Val Accuracy: 0.9266\n",
      "Epoch [407/1000], Loss: 0.0668, Accuracy: 0.9342 Val Accuracy: 0.9316\n",
      "Epoch [408/1000], Loss: 0.0488, Accuracy: 0.9494 Val Accuracy: 0.9468\n",
      "Epoch [409/1000], Loss: 0.0517, Accuracy: 0.9367 Val Accuracy: 0.9342\n",
      "Epoch [410/1000], Loss: 0.0683, Accuracy: 0.9342 Val Accuracy: 0.9468\n",
      "Epoch [411/1000], Loss: 0.0349, Accuracy: 0.9519 Val Accuracy: 0.9494\n",
      "Epoch [412/1000], Loss: 0.0146, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [413/1000], Loss: 0.0123, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [414/1000], Loss: 0.0092, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [415/1000], Loss: 0.0103, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [416/1000], Loss: 0.0126, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [417/1000], Loss: 0.0154, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [418/1000], Loss: 0.0171, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [419/1000], Loss: 0.0185, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [420/1000], Loss: 0.0269, Accuracy: 0.9544 Val Accuracy: 0.9544\n",
      "Epoch [421/1000], Loss: 0.0176, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [422/1000], Loss: 0.0097, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [423/1000], Loss: 0.0080, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [424/1000], Loss: 0.0126, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [425/1000], Loss: 0.0105, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [426/1000], Loss: 0.0140, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [427/1000], Loss: 0.0152, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [428/1000], Loss: 0.0109, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [429/1000], Loss: 0.0100, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [430/1000], Loss: 0.0126, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [431/1000], Loss: 0.0306, Accuracy: 0.9494 Val Accuracy: 0.9519\n",
      "Epoch [432/1000], Loss: 0.0656, Accuracy: 0.9367 Val Accuracy: 0.9544\n",
      "Epoch [433/1000], Loss: 0.0355, Accuracy: 0.9468 Val Accuracy: 0.9544\n",
      "Epoch [434/1000], Loss: 0.0278, Accuracy: 0.9519 Val Accuracy: 0.9468\n",
      "Epoch [435/1000], Loss: 0.0280, Accuracy: 0.9544 Val Accuracy: 0.9519\n",
      "Epoch [436/1000], Loss: 0.0317, Accuracy: 0.9519 Val Accuracy: 0.9494\n",
      "Epoch [437/1000], Loss: 0.0323, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [438/1000], Loss: 0.0192, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [439/1000], Loss: 0.0175, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [440/1000], Loss: 0.0087, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [441/1000], Loss: 0.0148, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [442/1000], Loss: 0.0212, Accuracy: 0.9519 Val Accuracy: 0.9620\n",
      "Epoch [443/1000], Loss: 0.0180, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [444/1000], Loss: 0.0278, Accuracy: 0.9519 Val Accuracy: 0.9468\n",
      "Epoch [445/1000], Loss: 0.0166, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [446/1000], Loss: 0.0214, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [447/1000], Loss: 0.0112, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [448/1000], Loss: 0.0107, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [449/1000], Loss: 0.0167, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [450/1000], Loss: 0.0099, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [451/1000], Loss: 0.0089, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [452/1000], Loss: 0.0045, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [453/1000], Loss: 0.0042, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [454/1000], Loss: 0.0045, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [455/1000], Loss: 0.0049, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [456/1000], Loss: 0.0040, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [457/1000], Loss: 0.0038, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [458/1000], Loss: 0.0104, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [459/1000], Loss: 0.0065, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [460/1000], Loss: 0.0091, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [461/1000], Loss: 0.0095, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [462/1000], Loss: 0.0054, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [463/1000], Loss: 0.0095, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [464/1000], Loss: 0.0080, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [465/1000], Loss: 0.0063, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [466/1000], Loss: 0.0116, Accuracy: 0.9595 Val Accuracy: 0.9519\n",
      "Epoch [467/1000], Loss: 0.0094, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [468/1000], Loss: 0.0112, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [469/1000], Loss: 0.0109, Accuracy: 0.9595 Val Accuracy: 0.9519\n",
      "Epoch [470/1000], Loss: 0.0127, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [471/1000], Loss: 0.0123, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [472/1000], Loss: 0.0227, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [473/1000], Loss: 0.0185, Accuracy: 0.9570 Val Accuracy: 0.9519\n",
      "Epoch [474/1000], Loss: 0.0213, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [475/1000], Loss: 0.0192, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [476/1000], Loss: 0.0164, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [477/1000], Loss: 0.0228, Accuracy: 0.9544 Val Accuracy: 0.9494\n",
      "Epoch [478/1000], Loss: 0.0163, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [479/1000], Loss: 0.0083, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [480/1000], Loss: 0.0048, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [481/1000], Loss: 0.0157, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [482/1000], Loss: 0.0159, Accuracy: 0.9570 Val Accuracy: 0.9519\n",
      "Epoch [483/1000], Loss: 0.0496, Accuracy: 0.9367 Val Accuracy: 0.9519\n",
      "Epoch [484/1000], Loss: 0.0705, Accuracy: 0.9443 Val Accuracy: 0.9342\n",
      "Epoch [485/1000], Loss: 0.0310, Accuracy: 0.9468 Val Accuracy: 0.9595\n",
      "Epoch [486/1000], Loss: 0.0411, Accuracy: 0.9494 Val Accuracy: 0.9291\n",
      "Epoch [487/1000], Loss: 0.0593, Accuracy: 0.9418 Val Accuracy: 0.9544\n",
      "Epoch [488/1000], Loss: 0.0359, Accuracy: 0.9519 Val Accuracy: 0.9620\n",
      "Epoch [489/1000], Loss: 0.0357, Accuracy: 0.9468 Val Accuracy: 0.9418\n",
      "Epoch [490/1000], Loss: 0.0590, Accuracy: 0.9443 Val Accuracy: 0.9519\n",
      "Epoch [491/1000], Loss: 0.0858, Accuracy: 0.9342 Val Accuracy: 0.9443\n",
      "Epoch [492/1000], Loss: 0.0602, Accuracy: 0.9342 Val Accuracy: 0.9519\n",
      "Epoch [493/1000], Loss: 0.0670, Accuracy: 0.9367 Val Accuracy: 0.9519\n",
      "Epoch [494/1000], Loss: 0.0340, Accuracy: 0.9519 Val Accuracy: 0.9494\n",
      "Epoch [495/1000], Loss: 0.0271, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [496/1000], Loss: 0.0234, Accuracy: 0.9519 Val Accuracy: 0.9595\n",
      "Epoch [497/1000], Loss: 0.0371, Accuracy: 0.9494 Val Accuracy: 0.9595\n",
      "Epoch [498/1000], Loss: 0.0405, Accuracy: 0.9418 Val Accuracy: 0.9570\n",
      "Epoch [499/1000], Loss: 0.0167, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [500/1000], Loss: 0.0140, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [501/1000], Loss: 0.0199, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [502/1000], Loss: 0.0127, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [503/1000], Loss: 0.0137, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [504/1000], Loss: 0.0148, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [505/1000], Loss: 0.0270, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [506/1000], Loss: 0.0128, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [507/1000], Loss: 0.0068, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [508/1000], Loss: 0.0106, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [509/1000], Loss: 0.0053, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [510/1000], Loss: 0.0064, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [511/1000], Loss: 0.0065, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [512/1000], Loss: 0.0170, Accuracy: 0.9570 Val Accuracy: 0.9494\n",
      "Epoch [513/1000], Loss: 0.0160, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [514/1000], Loss: 0.0214, Accuracy: 0.9519 Val Accuracy: 0.9620\n",
      "Epoch [515/1000], Loss: 0.0133, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [516/1000], Loss: 0.0081, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [517/1000], Loss: 0.0099, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [518/1000], Loss: 0.0051, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [519/1000], Loss: 0.0042, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [520/1000], Loss: 0.0056, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [521/1000], Loss: 0.0050, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [522/1000], Loss: 0.0100, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [523/1000], Loss: 0.0145, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [524/1000], Loss: 0.0074, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [525/1000], Loss: 0.0035, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [526/1000], Loss: 0.0063, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [527/1000], Loss: 0.0156, Accuracy: 0.9595 Val Accuracy: 0.9519\n",
      "Epoch [528/1000], Loss: 0.0255, Accuracy: 0.9519 Val Accuracy: 0.9570\n",
      "Epoch [529/1000], Loss: 0.0333, Accuracy: 0.9494 Val Accuracy: 0.9342\n",
      "Epoch [530/1000], Loss: 0.0751, Accuracy: 0.9418 Val Accuracy: 0.9418\n",
      "Epoch [531/1000], Loss: 0.0263, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [532/1000], Loss: 0.0249, Accuracy: 0.9544 Val Accuracy: 0.9544\n",
      "Epoch [533/1000], Loss: 0.0260, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [534/1000], Loss: 0.0286, Accuracy: 0.9519 Val Accuracy: 0.9544\n",
      "Epoch [535/1000], Loss: 0.0188, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [536/1000], Loss: 0.0320, Accuracy: 0.9544 Val Accuracy: 0.9620\n",
      "Epoch [537/1000], Loss: 0.0235, Accuracy: 0.9544 Val Accuracy: 0.9494\n",
      "Epoch [538/1000], Loss: 0.0405, Accuracy: 0.9468 Val Accuracy: 0.9494\n",
      "Epoch [539/1000], Loss: 0.0876, Accuracy: 0.9367 Val Accuracy: 0.9089\n",
      "Epoch [540/1000], Loss: 0.0607, Accuracy: 0.9392 Val Accuracy: 0.9519\n",
      "Epoch [541/1000], Loss: 0.0434, Accuracy: 0.9519 Val Accuracy: 0.9468\n",
      "Epoch [542/1000], Loss: 0.0287, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [543/1000], Loss: 0.0122, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [544/1000], Loss: 0.0106, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [545/1000], Loss: 0.0120, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [546/1000], Loss: 0.0148, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [547/1000], Loss: 0.0104, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [548/1000], Loss: 0.0082, Accuracy: 0.9620 Val Accuracy: 0.9544\n",
      "Epoch [549/1000], Loss: 0.0132, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [550/1000], Loss: 0.0134, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [551/1000], Loss: 0.0235, Accuracy: 0.9570 Val Accuracy: 0.9519\n",
      "Epoch [552/1000], Loss: 0.0085, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [553/1000], Loss: 0.0098, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [554/1000], Loss: 0.0188, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [555/1000], Loss: 0.0092, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [556/1000], Loss: 0.0073, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [557/1000], Loss: 0.0069, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [558/1000], Loss: 0.0037, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [559/1000], Loss: 0.0079, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [560/1000], Loss: 0.0072, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [561/1000], Loss: 0.0041, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [562/1000], Loss: 0.0069, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [563/1000], Loss: 0.0068, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [564/1000], Loss: 0.0032, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [565/1000], Loss: 0.0045, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [566/1000], Loss: 0.0036, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [567/1000], Loss: 0.0048, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [568/1000], Loss: 0.0044, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [569/1000], Loss: 0.0042, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [570/1000], Loss: 0.0061, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [571/1000], Loss: 0.0036, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [572/1000], Loss: 0.0041, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [573/1000], Loss: 0.0031, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [574/1000], Loss: 0.0044, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [575/1000], Loss: 0.0036, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [576/1000], Loss: 0.0041, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [577/1000], Loss: 0.0036, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [578/1000], Loss: 0.0093, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [579/1000], Loss: 0.0167, Accuracy: 0.9544 Val Accuracy: 0.9620\n",
      "Epoch [580/1000], Loss: 0.0244, Accuracy: 0.9494 Val Accuracy: 0.9544\n",
      "Epoch [581/1000], Loss: 0.0520, Accuracy: 0.9468 Val Accuracy: 0.9519\n",
      "Epoch [582/1000], Loss: 0.0442, Accuracy: 0.9392 Val Accuracy: 0.9316\n",
      "Epoch [583/1000], Loss: 0.0278, Accuracy: 0.9494 Val Accuracy: 0.9468\n",
      "Epoch [584/1000], Loss: 0.0122, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [585/1000], Loss: 0.0052, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [586/1000], Loss: 0.0050, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [587/1000], Loss: 0.0114, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [588/1000], Loss: 0.0221, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [589/1000], Loss: 0.0106, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [590/1000], Loss: 0.0262, Accuracy: 0.9519 Val Accuracy: 0.9620\n",
      "Epoch [591/1000], Loss: 0.0307, Accuracy: 0.9519 Val Accuracy: 0.9570\n",
      "Epoch [592/1000], Loss: 0.0123, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [593/1000], Loss: 0.0157, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [594/1000], Loss: 0.0164, Accuracy: 0.9544 Val Accuracy: 0.9544\n",
      "Epoch [595/1000], Loss: 0.0133, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [596/1000], Loss: 0.0168, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [597/1000], Loss: 0.0199, Accuracy: 0.9570 Val Accuracy: 0.9443\n",
      "Epoch [598/1000], Loss: 0.0126, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [599/1000], Loss: 0.0325, Accuracy: 0.9494 Val Accuracy: 0.9595\n",
      "Epoch [600/1000], Loss: 0.0383, Accuracy: 0.9494 Val Accuracy: 0.9519\n",
      "Epoch [601/1000], Loss: 0.0346, Accuracy: 0.9519 Val Accuracy: 0.9519\n",
      "Epoch [602/1000], Loss: 0.0316, Accuracy: 0.9519 Val Accuracy: 0.9494\n",
      "Epoch [603/1000], Loss: 0.0134, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [604/1000], Loss: 0.0103, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [605/1000], Loss: 0.0128, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [606/1000], Loss: 0.0493, Accuracy: 0.9468 Val Accuracy: 0.9519\n",
      "Epoch [607/1000], Loss: 0.0714, Accuracy: 0.9291 Val Accuracy: 0.9342\n",
      "Epoch [608/1000], Loss: 0.0438, Accuracy: 0.9494 Val Accuracy: 0.9468\n",
      "Epoch [609/1000], Loss: 0.0726, Accuracy: 0.9367 Val Accuracy: 0.9266\n",
      "Epoch [610/1000], Loss: 0.0534, Accuracy: 0.9468 Val Accuracy: 0.9342\n",
      "Epoch [611/1000], Loss: 0.0222, Accuracy: 0.9519 Val Accuracy: 0.9570\n",
      "Epoch [612/1000], Loss: 0.0136, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [613/1000], Loss: 0.0219, Accuracy: 0.9544 Val Accuracy: 0.9544\n",
      "Epoch [614/1000], Loss: 0.0162, Accuracy: 0.9519 Val Accuracy: 0.9620\n",
      "Epoch [615/1000], Loss: 0.0115, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [616/1000], Loss: 0.0058, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [617/1000], Loss: 0.0097, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [618/1000], Loss: 0.0127, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [619/1000], Loss: 0.0169, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [620/1000], Loss: 0.0051, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [621/1000], Loss: 0.0074, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [622/1000], Loss: 0.0023, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [623/1000], Loss: 0.0110, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [624/1000], Loss: 0.0112, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [625/1000], Loss: 0.0085, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [626/1000], Loss: 0.0123, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [627/1000], Loss: 0.0046, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [628/1000], Loss: 0.0092, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [629/1000], Loss: 0.0086, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [630/1000], Loss: 0.0040, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [631/1000], Loss: 0.0063, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [632/1000], Loss: 0.0112, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [633/1000], Loss: 0.0043, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [634/1000], Loss: 0.0071, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [635/1000], Loss: 0.0047, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [636/1000], Loss: 0.0054, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [637/1000], Loss: 0.0031, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [638/1000], Loss: 0.0022, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [639/1000], Loss: 0.0022, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [640/1000], Loss: 0.0037, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [641/1000], Loss: 0.0018, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [642/1000], Loss: 0.0041, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [643/1000], Loss: 0.0050, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [644/1000], Loss: 0.0098, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [645/1000], Loss: 0.0138, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [646/1000], Loss: 0.0102, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [647/1000], Loss: 0.0068, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [648/1000], Loss: 0.0063, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [649/1000], Loss: 0.0040, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [650/1000], Loss: 0.0040, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [651/1000], Loss: 0.0199, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [652/1000], Loss: 0.0222, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [653/1000], Loss: 0.0118, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [654/1000], Loss: 0.0394, Accuracy: 0.9544 Val Accuracy: 0.9544\n",
      "Epoch [655/1000], Loss: 0.0228, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [656/1000], Loss: 0.0152, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [657/1000], Loss: 0.0257, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [658/1000], Loss: 0.0224, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [659/1000], Loss: 0.0135, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [660/1000], Loss: 0.0222, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [661/1000], Loss: 0.0198, Accuracy: 0.9519 Val Accuracy: 0.9468\n",
      "Epoch [662/1000], Loss: 0.0163, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [663/1000], Loss: 0.0157, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [664/1000], Loss: 0.0162, Accuracy: 0.9595 Val Accuracy: 0.9494\n",
      "Epoch [665/1000], Loss: 0.0179, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [666/1000], Loss: 0.0087, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [667/1000], Loss: 0.0047, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [668/1000], Loss: 0.0169, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [669/1000], Loss: 0.0267, Accuracy: 0.9519 Val Accuracy: 0.9620\n",
      "Epoch [670/1000], Loss: 0.0415, Accuracy: 0.9519 Val Accuracy: 0.9570\n",
      "Epoch [671/1000], Loss: 0.0274, Accuracy: 0.9544 Val Accuracy: 0.9494\n",
      "Epoch [672/1000], Loss: 0.0153, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [673/1000], Loss: 0.0061, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [674/1000], Loss: 0.0056, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [675/1000], Loss: 0.0045, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [676/1000], Loss: 0.0026, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [677/1000], Loss: 0.0032, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [678/1000], Loss: 0.0028, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [679/1000], Loss: 0.0046, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [680/1000], Loss: 0.0021, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [681/1000], Loss: 0.0028, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [682/1000], Loss: 0.0016, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [683/1000], Loss: 0.0017, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [684/1000], Loss: 0.0021, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [685/1000], Loss: 0.0034, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [686/1000], Loss: 0.0051, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [687/1000], Loss: 0.0086, Accuracy: 0.9595 Val Accuracy: 0.9494\n",
      "Epoch [688/1000], Loss: 0.0306, Accuracy: 0.9544 Val Accuracy: 0.9494\n",
      "Epoch [689/1000], Loss: 0.0085, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [690/1000], Loss: 0.0096, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [691/1000], Loss: 0.0068, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [692/1000], Loss: 0.0090, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [693/1000], Loss: 0.0030, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [694/1000], Loss: 0.0303, Accuracy: 0.9544 Val Accuracy: 0.9241\n",
      "Epoch [695/1000], Loss: 0.0574, Accuracy: 0.9367 Val Accuracy: 0.9367\n",
      "Epoch [696/1000], Loss: 0.0608, Accuracy: 0.9418 Val Accuracy: 0.9570\n",
      "Epoch [697/1000], Loss: 0.0485, Accuracy: 0.9468 Val Accuracy: 0.9291\n",
      "Epoch [698/1000], Loss: 0.0320, Accuracy: 0.9544 Val Accuracy: 0.9519\n",
      "Epoch [699/1000], Loss: 0.0340, Accuracy: 0.9519 Val Accuracy: 0.9620\n",
      "Epoch [700/1000], Loss: 0.0188, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [701/1000], Loss: 0.0150, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [702/1000], Loss: 0.0121, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [703/1000], Loss: 0.0275, Accuracy: 0.9519 Val Accuracy: 0.9468\n",
      "Epoch [704/1000], Loss: 0.0367, Accuracy: 0.9468 Val Accuracy: 0.9544\n",
      "Epoch [705/1000], Loss: 0.0268, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [706/1000], Loss: 0.0129, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [707/1000], Loss: 0.0105, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [708/1000], Loss: 0.0084, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [709/1000], Loss: 0.0113, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [710/1000], Loss: 0.0055, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [711/1000], Loss: 0.0064, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [712/1000], Loss: 0.0073, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [713/1000], Loss: 0.0096, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [714/1000], Loss: 0.0044, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [715/1000], Loss: 0.0082, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [716/1000], Loss: 0.0065, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [717/1000], Loss: 0.0047, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [718/1000], Loss: 0.0095, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [719/1000], Loss: 0.0158, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [720/1000], Loss: 0.0166, Accuracy: 0.9544 Val Accuracy: 0.9494\n",
      "Epoch [721/1000], Loss: 0.0253, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [722/1000], Loss: 0.0079, Accuracy: 0.9595 Val Accuracy: 0.9519\n",
      "Epoch [723/1000], Loss: 0.0330, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [724/1000], Loss: 0.0364, Accuracy: 0.9494 Val Accuracy: 0.9620\n",
      "Epoch [725/1000], Loss: 0.0255, Accuracy: 0.9544 Val Accuracy: 0.9494\n",
      "Epoch [726/1000], Loss: 0.0418, Accuracy: 0.9468 Val Accuracy: 0.9570\n",
      "Epoch [727/1000], Loss: 0.0391, Accuracy: 0.9443 Val Accuracy: 0.9494\n",
      "Epoch [728/1000], Loss: 0.0420, Accuracy: 0.9443 Val Accuracy: 0.9570\n",
      "Epoch [729/1000], Loss: 0.0261, Accuracy: 0.9519 Val Accuracy: 0.9519\n",
      "Epoch [730/1000], Loss: 0.0456, Accuracy: 0.9519 Val Accuracy: 0.9570\n",
      "Epoch [731/1000], Loss: 0.0379, Accuracy: 0.9468 Val Accuracy: 0.9443\n",
      "Epoch [732/1000], Loss: 0.0272, Accuracy: 0.9494 Val Accuracy: 0.9570\n",
      "Epoch [733/1000], Loss: 0.0235, Accuracy: 0.9544 Val Accuracy: 0.9519\n",
      "Epoch [734/1000], Loss: 0.0104, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [735/1000], Loss: 0.0200, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [736/1000], Loss: 0.0205, Accuracy: 0.9519 Val Accuracy: 0.9519\n",
      "Epoch [737/1000], Loss: 0.0173, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [738/1000], Loss: 0.0168, Accuracy: 0.9544 Val Accuracy: 0.9519\n",
      "Epoch [739/1000], Loss: 0.0177, Accuracy: 0.9570 Val Accuracy: 0.9519\n",
      "Epoch [740/1000], Loss: 0.0217, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [741/1000], Loss: 0.0082, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [742/1000], Loss: 0.0072, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [743/1000], Loss: 0.0049, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [744/1000], Loss: 0.0022, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [745/1000], Loss: 0.0063, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [746/1000], Loss: 0.0062, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [747/1000], Loss: 0.0017, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [748/1000], Loss: 0.0028, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [749/1000], Loss: 0.0071, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [750/1000], Loss: 0.0027, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [751/1000], Loss: 0.0024, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [752/1000], Loss: 0.0030, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [753/1000], Loss: 0.0017, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [754/1000], Loss: 0.0026, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [755/1000], Loss: 0.0012, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [756/1000], Loss: 0.0091, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [757/1000], Loss: 0.0024, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [758/1000], Loss: 0.0034, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [759/1000], Loss: 0.0034, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [760/1000], Loss: 0.0030, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [761/1000], Loss: 0.0037, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [762/1000], Loss: 0.0016, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [763/1000], Loss: 0.0016, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [764/1000], Loss: 0.0019, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [765/1000], Loss: 0.0024, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [766/1000], Loss: 0.0022, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [767/1000], Loss: 0.0027, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [768/1000], Loss: 0.0069, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [769/1000], Loss: 0.0123, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [770/1000], Loss: 0.0125, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [771/1000], Loss: 0.0106, Accuracy: 0.9620 Val Accuracy: 0.9544\n",
      "Epoch [772/1000], Loss: 0.0095, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [773/1000], Loss: 0.0091, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [774/1000], Loss: 0.0152, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [775/1000], Loss: 0.0274, Accuracy: 0.9519 Val Accuracy: 0.9595\n",
      "Epoch [776/1000], Loss: 0.0355, Accuracy: 0.9519 Val Accuracy: 0.9468\n",
      "Epoch [777/1000], Loss: 0.0161, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [778/1000], Loss: 0.0118, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [779/1000], Loss: 0.0081, Accuracy: 0.9620 Val Accuracy: 0.9544\n",
      "Epoch [780/1000], Loss: 0.0083, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [781/1000], Loss: 0.0049, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [782/1000], Loss: 0.0037, Accuracy: 0.9620 Val Accuracy: 0.9519\n",
      "Epoch [783/1000], Loss: 0.0042, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [784/1000], Loss: 0.0032, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [785/1000], Loss: 0.0036, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [786/1000], Loss: 0.0021, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [787/1000], Loss: 0.0045, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [788/1000], Loss: 0.0032, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [789/1000], Loss: 0.0032, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [790/1000], Loss: 0.0025, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [791/1000], Loss: 0.0024, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [792/1000], Loss: 0.0020, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [793/1000], Loss: 0.0030, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [794/1000], Loss: 0.0016, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [795/1000], Loss: 0.0018, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [796/1000], Loss: 0.0016, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [797/1000], Loss: 0.0007, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [798/1000], Loss: 0.0015, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [799/1000], Loss: 0.0018, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [800/1000], Loss: 0.0027, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [801/1000], Loss: 0.0012, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [802/1000], Loss: 0.0030, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [803/1000], Loss: 0.0037, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [804/1000], Loss: 0.0125, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [805/1000], Loss: 0.0106, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [806/1000], Loss: 0.0153, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [807/1000], Loss: 0.0093, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [808/1000], Loss: 0.0071, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [809/1000], Loss: 0.0055, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [810/1000], Loss: 0.0125, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [811/1000], Loss: 0.0124, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [812/1000], Loss: 0.0132, Accuracy: 0.9570 Val Accuracy: 0.9468\n",
      "Epoch [813/1000], Loss: 0.1101, Accuracy: 0.9342 Val Accuracy: 0.9519\n",
      "Epoch [814/1000], Loss: 0.0516, Accuracy: 0.9392 Val Accuracy: 0.9544\n",
      "Epoch [815/1000], Loss: 0.0256, Accuracy: 0.9570 Val Accuracy: 0.9494\n",
      "Epoch [816/1000], Loss: 0.0329, Accuracy: 0.9494 Val Accuracy: 0.9544\n",
      "Epoch [817/1000], Loss: 0.0386, Accuracy: 0.9494 Val Accuracy: 0.9291\n",
      "Epoch [818/1000], Loss: 0.0735, Accuracy: 0.9316 Val Accuracy: 0.9570\n",
      "Epoch [819/1000], Loss: 0.0514, Accuracy: 0.9443 Val Accuracy: 0.9291\n",
      "Epoch [820/1000], Loss: 0.0657, Accuracy: 0.9392 Val Accuracy: 0.9316\n",
      "Epoch [821/1000], Loss: 0.0862, Accuracy: 0.9392 Val Accuracy: 0.9570\n",
      "Epoch [822/1000], Loss: 0.0281, Accuracy: 0.9519 Val Accuracy: 0.9519\n",
      "Epoch [823/1000], Loss: 0.0255, Accuracy: 0.9519 Val Accuracy: 0.9570\n",
      "Epoch [824/1000], Loss: 0.0122, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [825/1000], Loss: 0.0216, Accuracy: 0.9519 Val Accuracy: 0.9595\n",
      "Epoch [826/1000], Loss: 0.0139, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [827/1000], Loss: 0.0088, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [828/1000], Loss: 0.0060, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [829/1000], Loss: 0.0062, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [830/1000], Loss: 0.0039, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [831/1000], Loss: 0.0053, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [832/1000], Loss: 0.0135, Accuracy: 0.9544 Val Accuracy: 0.9620\n",
      "Epoch [833/1000], Loss: 0.0088, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [834/1000], Loss: 0.0239, Accuracy: 0.9519 Val Accuracy: 0.9468\n",
      "Epoch [835/1000], Loss: 0.0378, Accuracy: 0.9468 Val Accuracy: 0.9367\n",
      "Epoch [836/1000], Loss: 0.0476, Accuracy: 0.9443 Val Accuracy: 0.9367\n",
      "Epoch [837/1000], Loss: 0.0611, Accuracy: 0.9392 Val Accuracy: 0.9595\n",
      "Epoch [838/1000], Loss: 0.0365, Accuracy: 0.9519 Val Accuracy: 0.9595\n",
      "Epoch [839/1000], Loss: 0.0106, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [840/1000], Loss: 0.0110, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [841/1000], Loss: 0.0093, Accuracy: 0.9595 Val Accuracy: 0.9519\n",
      "Epoch [842/1000], Loss: 0.0038, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [843/1000], Loss: 0.0024, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [844/1000], Loss: 0.0088, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [845/1000], Loss: 0.0094, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [846/1000], Loss: 0.0118, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [847/1000], Loss: 0.0176, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [848/1000], Loss: 0.0303, Accuracy: 0.9494 Val Accuracy: 0.9519\n",
      "Epoch [849/1000], Loss: 0.0189, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [850/1000], Loss: 0.0064, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [851/1000], Loss: 0.0032, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [852/1000], Loss: 0.0058, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [853/1000], Loss: 0.0023, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [854/1000], Loss: 0.0045, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [855/1000], Loss: 0.0031, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [856/1000], Loss: 0.0046, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [857/1000], Loss: 0.0021, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [858/1000], Loss: 0.0025, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [859/1000], Loss: 0.0044, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [860/1000], Loss: 0.0071, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [861/1000], Loss: 0.0058, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [862/1000], Loss: 0.0109, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [863/1000], Loss: 0.0098, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [864/1000], Loss: 0.0104, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [865/1000], Loss: 0.0129, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [866/1000], Loss: 0.0056, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [867/1000], Loss: 0.0052, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [868/1000], Loss: 0.0082, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [869/1000], Loss: 0.0077, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [870/1000], Loss: 0.0063, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [871/1000], Loss: 0.0065, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [872/1000], Loss: 0.0118, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [873/1000], Loss: 0.0062, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [874/1000], Loss: 0.0032, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [875/1000], Loss: 0.0021, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [876/1000], Loss: 0.0116, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [877/1000], Loss: 0.0285, Accuracy: 0.9494 Val Accuracy: 0.9570\n",
      "Epoch [878/1000], Loss: 0.0089, Accuracy: 0.9595 Val Accuracy: 0.9519\n",
      "Epoch [879/1000], Loss: 0.0085, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [880/1000], Loss: 0.0176, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [881/1000], Loss: 0.0048, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [882/1000], Loss: 0.0107, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [883/1000], Loss: 0.0194, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [884/1000], Loss: 0.0107, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [885/1000], Loss: 0.0168, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [886/1000], Loss: 0.0116, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [887/1000], Loss: 0.0185, Accuracy: 0.9570 Val Accuracy: 0.9418\n",
      "Epoch [888/1000], Loss: 0.0112, Accuracy: 0.9570 Val Accuracy: 0.9494\n",
      "Epoch [889/1000], Loss: 0.0077, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [890/1000], Loss: 0.0018, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [891/1000], Loss: 0.0246, Accuracy: 0.9519 Val Accuracy: 0.9519\n",
      "Epoch [892/1000], Loss: 0.0230, Accuracy: 0.9544 Val Accuracy: 0.9367\n",
      "Epoch [893/1000], Loss: 0.0271, Accuracy: 0.9519 Val Accuracy: 0.9570\n",
      "Epoch [894/1000], Loss: 0.0160, Accuracy: 0.9570 Val Accuracy: 0.9519\n",
      "Epoch [895/1000], Loss: 0.0123, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [896/1000], Loss: 0.0178, Accuracy: 0.9519 Val Accuracy: 0.9519\n",
      "Epoch [897/1000], Loss: 0.0198, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [898/1000], Loss: 0.0126, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [899/1000], Loss: 0.0186, Accuracy: 0.9544 Val Accuracy: 0.9494\n",
      "Epoch [900/1000], Loss: 0.0174, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [901/1000], Loss: 0.0090, Accuracy: 0.9595 Val Accuracy: 0.9544\n",
      "Epoch [902/1000], Loss: 0.0052, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [903/1000], Loss: 0.0066, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [904/1000], Loss: 0.0052, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [905/1000], Loss: 0.0034, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [906/1000], Loss: 0.0051, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [907/1000], Loss: 0.0099, Accuracy: 0.9570 Val Accuracy: 0.9595\n",
      "Epoch [908/1000], Loss: 0.0169, Accuracy: 0.9570 Val Accuracy: 0.9519\n",
      "Epoch [909/1000], Loss: 0.0217, Accuracy: 0.9544 Val Accuracy: 0.9620\n",
      "Epoch [910/1000], Loss: 0.0106, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [911/1000], Loss: 0.0242, Accuracy: 0.9519 Val Accuracy: 0.9620\n",
      "Epoch [912/1000], Loss: 0.0112, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [913/1000], Loss: 0.0054, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [914/1000], Loss: 0.0085, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [915/1000], Loss: 0.0048, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [916/1000], Loss: 0.0028, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [917/1000], Loss: 0.0049, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [918/1000], Loss: 0.0040, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [919/1000], Loss: 0.0022, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [920/1000], Loss: 0.0010, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [921/1000], Loss: 0.0038, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [922/1000], Loss: 0.0025, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [923/1000], Loss: 0.0038, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [924/1000], Loss: 0.0021, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [925/1000], Loss: 0.0014, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [926/1000], Loss: 0.0009, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [927/1000], Loss: 0.0018, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [928/1000], Loss: 0.0014, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [929/1000], Loss: 0.0014, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [930/1000], Loss: 0.0010, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [931/1000], Loss: 0.0016, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [932/1000], Loss: 0.0012, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [933/1000], Loss: 0.0013, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [934/1000], Loss: 0.0017, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [935/1000], Loss: 0.0010, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [936/1000], Loss: 0.0011, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [937/1000], Loss: 0.0018, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [938/1000], Loss: 0.0024, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [939/1000], Loss: 0.0020, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [940/1000], Loss: 0.0008, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [941/1000], Loss: 0.0018, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [942/1000], Loss: 0.0016, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [943/1000], Loss: 0.0013, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [944/1000], Loss: 0.0014, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [945/1000], Loss: 0.0011, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [946/1000], Loss: 0.0046, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [947/1000], Loss: 0.0053, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [948/1000], Loss: 0.0023, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [949/1000], Loss: 0.0018, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [950/1000], Loss: 0.0022, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [951/1000], Loss: 0.0005, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [952/1000], Loss: 0.0012, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [953/1000], Loss: 0.0021, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [954/1000], Loss: 0.0012, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [955/1000], Loss: 0.0005, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [956/1000], Loss: 0.0025, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [957/1000], Loss: 0.0092, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [958/1000], Loss: 0.0035, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [959/1000], Loss: 0.0082, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [960/1000], Loss: 0.0084, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [961/1000], Loss: 0.0097, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [962/1000], Loss: 0.0238, Accuracy: 0.9544 Val Accuracy: 0.9570\n",
      "Epoch [963/1000], Loss: 0.0190, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [964/1000], Loss: 0.0247, Accuracy: 0.9570 Val Accuracy: 0.9570\n",
      "Epoch [965/1000], Loss: 0.0181, Accuracy: 0.9519 Val Accuracy: 0.9620\n",
      "Epoch [966/1000], Loss: 0.0098, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [967/1000], Loss: 0.0246, Accuracy: 0.9494 Val Accuracy: 0.9570\n",
      "Epoch [968/1000], Loss: 0.0185, Accuracy: 0.9570 Val Accuracy: 0.9544\n",
      "Epoch [969/1000], Loss: 0.1210, Accuracy: 0.9215 Val Accuracy: 0.9418\n",
      "Epoch [970/1000], Loss: 0.0878, Accuracy: 0.9342 Val Accuracy: 0.9215\n",
      "Epoch [971/1000], Loss: 0.0440, Accuracy: 0.9519 Val Accuracy: 0.9392\n",
      "Epoch [972/1000], Loss: 0.0510, Accuracy: 0.9468 Val Accuracy: 0.9595\n",
      "Epoch [973/1000], Loss: 0.0307, Accuracy: 0.9544 Val Accuracy: 0.9519\n",
      "Epoch [974/1000], Loss: 0.0666, Accuracy: 0.9392 Val Accuracy: 0.9494\n",
      "Epoch [975/1000], Loss: 0.0615, Accuracy: 0.9392 Val Accuracy: 0.9544\n",
      "Epoch [976/1000], Loss: 0.0780, Accuracy: 0.9418 Val Accuracy: 0.9544\n",
      "Epoch [977/1000], Loss: 0.0436, Accuracy: 0.9468 Val Accuracy: 0.9418\n",
      "Epoch [978/1000], Loss: 0.0288, Accuracy: 0.9494 Val Accuracy: 0.9468\n",
      "Epoch [979/1000], Loss: 0.0957, Accuracy: 0.9342 Val Accuracy: 0.9342\n",
      "Epoch [980/1000], Loss: 0.0472, Accuracy: 0.9418 Val Accuracy: 0.9570\n",
      "Epoch [981/1000], Loss: 0.0308, Accuracy: 0.9494 Val Accuracy: 0.9519\n",
      "Epoch [982/1000], Loss: 0.0547, Accuracy: 0.9418 Val Accuracy: 0.9544\n",
      "Epoch [983/1000], Loss: 0.0431, Accuracy: 0.9418 Val Accuracy: 0.9468\n",
      "Epoch [984/1000], Loss: 0.0249, Accuracy: 0.9544 Val Accuracy: 0.9494\n",
      "Epoch [985/1000], Loss: 0.0213, Accuracy: 0.9544 Val Accuracy: 0.9519\n",
      "Epoch [986/1000], Loss: 0.0257, Accuracy: 0.9544 Val Accuracy: 0.9595\n",
      "Epoch [987/1000], Loss: 0.0077, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [988/1000], Loss: 0.0143, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [989/1000], Loss: 0.0088, Accuracy: 0.9595 Val Accuracy: 0.9595\n",
      "Epoch [990/1000], Loss: 0.0054, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [991/1000], Loss: 0.0140, Accuracy: 0.9570 Val Accuracy: 0.9620\n",
      "Epoch [992/1000], Loss: 0.0062, Accuracy: 0.9595 Val Accuracy: 0.9570\n",
      "Epoch [993/1000], Loss: 0.0052, Accuracy: 0.9620 Val Accuracy: 0.9570\n",
      "Epoch [994/1000], Loss: 0.0027, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [995/1000], Loss: 0.0076, Accuracy: 0.9595 Val Accuracy: 0.9620\n",
      "Epoch [996/1000], Loss: 0.0044, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [997/1000], Loss: 0.0056, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [998/1000], Loss: 0.0047, Accuracy: 0.9620 Val Accuracy: 0.9620\n",
      "Epoch [999/1000], Loss: 0.0041, Accuracy: 0.9620 Val Accuracy: 0.9595\n",
      "Epoch [1000/1000], Loss: 0.0016, Accuracy: 0.9620 Val Accuracy: 0.9620\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(tfnetwork.parameters(), lr = 0.001)\n",
    "\n",
    "\n",
    "# print(i)\n",
    "# for train_features, train_labels in train_dl:\n",
    "#     i += 1\n",
    "#     print(i)\n",
    "n_epochs = 1000\n",
    "loss_hist_train = [0] * n_epochs\n",
    "accuracy_hist_train = [0] * n_epochs\n",
    "loss_hist_valid = [0] * n_epochs\n",
    "accuracy_hist_valid = [0] * n_epochs\n",
    "for epoch in range(n_epochs):\n",
    "    tfnetwork.train()\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = tfnetwork(x_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        \n",
    "        loss_hist_train[epoch] += loss.item() * y_batch.size(0)\n",
    "        accuracy_hist_train[epoch] += get_num_correct(pred, y_batch)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    loss_hist_train[epoch] /= float(len(train_dl.dataset))\n",
    "    accuracy_hist_train[epoch] /= float(len(train_dl.dataset))\n",
    "        \n",
    "\n",
    "    \n",
    "    # print('train_out.shape', train_out.shape)\n",
    "    accuracy = get_accuracy(pred, y_batch)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in train_dl:\n",
    "\n",
    "            # Forward pass\n",
    "            pred = tfnetwork(x_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "\n",
    "            loss_hist_valid[epoch] += loss.item() * y_batch.size(0)\n",
    "            accuracy_hist_valid[epoch] += get_num_correct(pred, y_batch)\n",
    "\n",
    "        loss_hist_valid[epoch] /= float(len(train_dl.dataset))\n",
    "        accuracy_hist_valid[epoch] /= float(len(train_dl.dataset))\n",
    "        \n",
    "    \n",
    "    #     tfnetwork.eval()\n",
    "    #     for x_batch, y_batch in valid_dl:\n",
    "    #         # Forward pass\n",
    "    #         pred = tfnetwork(x_batch)\n",
    "    #         loss = loss_fn(pred, y_batch)\n",
    "\n",
    "    #     tfnetwork.eval()\n",
    "    # valid_features, valid_labels = /\n",
    "    print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss_hist_train[epoch]:.4f}, Accuracy: {accuracy_hist_train[epoch]:.4f}'\n",
    "          f' Val Accuracy: {accuracy_hist_valid[epoch]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2b32d268-f2d2-4a29-bae5-14c9f8a07232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (positional_layer): Linear(in_features=1, out_features=36, bias=True)\n",
       "  (embed_layer): Linear(in_features=4, out_features=36, bias=True)\n",
       "  (encoderlayer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=36, out_features=36, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=36, out_features=100, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=100, out_features=36, bias=True)\n",
       "    (norm1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=36, out_features=36, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=36, out_features=100, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=100, out_features=36, bias=True)\n",
       "        (norm1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=36, out_features=36, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=36, out_features=100, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=100, out_features=36, bias=True)\n",
       "        (norm1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=36, out_features=36, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=36, out_features=100, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=100, out_features=36, bias=True)\n",
       "        (norm1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (class_encoder): Linear(in_features=36, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96f781e1-74da-46fc-a9bc-717cd19f2ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 36])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfnetwork_out = tfnetwork(tf_test)\n",
    "torch.max(tfnetwork_out,dim = 1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "785e5e8d-7579-4edf-8597-ada7443140e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf, -inf],\n",
       "        [0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(4, 4) * float('-inf'), diagonal=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afcaad30-981b-4a75-a214-de491bf2757c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac10e44-7ccd-4f4e-ab48-255648980338",
   "metadata": {},
   "source": [
    "## Old S2 pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8801cb4f-7504-4665-bd51-91a431e0d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class s2Dataset(Dataset):\n",
    "#     \"\"\"Sentinel 2 dataset\"\"\"\n",
    "    \n",
    "#     def __init__(self, proj_path, class_colname):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             proj_path (string): path to manclassify project\n",
    "#         \"\"\"\n",
    "#         self.proj_path = proj_path\n",
    "#         proj_normpath = os.path.normpath(proj_path)\n",
    "#         proj_dirname = proj_normpath.split(os.sep)[-1]\n",
    "#         self.proj_name = re.sub(\"_classification$\",\"\",proj_dirname)\n",
    "#         self.class_path = os.path.join(proj_path, self.proj_name + \"_classification\")\n",
    "#         self.ts_path = os.path.join(proj_path, self.proj_name + \"_download_timeseries\")\n",
    "#         self.pt_classes = pd.read_csv(os.path.join(self.class_path,\"location_classification.csv\"))\n",
    "#         self.pt_classes = classes[['loc_id', class_colname]].dropna()\n",
    "#         # self.pt_classes['loc_id'] = self.pt_classes['loc_id'] + 10.5 # for testing index only\n",
    "#         self.classes = pd.unique(self.pt_classes[class_colname])\n",
    "#         self.labels = self.pt_classes.assign(val = 1).pivot_table(columns = class_colname, index = 'loc_id', values = 'val', fill_value= 0)\n",
    "\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         loc_id = self.labels.index[idx]\n",
    "#         self.last_loc_id = loc_id\n",
    "        \n",
    "#         # select location id\n",
    "#         s2_ts_x = s2_ts[['B8','B4','B3','B2','day']]\n",
    "#         x = torch.tensor(s2_ts_x.to_numpy())\n",
    "        \n",
    "#         # get one-hot encoding for the point as tensor\n",
    "#         y = torch.tensor(self.labels.iloc[idx].to_numpy())\n",
    "        \n",
    "#         return x, y\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.pt_classes.shape[0]\n",
    "\n",
    "\n",
    "# proj_path = \"/Users/gopal/Google Drive/_Research/Research projects/ML/manclassify/app_data/Thailand\"\n",
    "# # date_rangeX = pd.to_datetime(['2019-06-01','2020-05-31'])\n",
    "# s2_train = s2Dataset(proj_path = proj_path, class_colname = 'Subclass2019')\n",
    "# x = s2_train.__getitem__(10)\n",
    "# sys.getsizeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54cfc2b-b5c5-431c-8fde-e544f42f543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_orig = loc_s1_ts_tensor\n",
    "day_col = 1\n",
    "def get_avg_days_to_nearest(tensor_orig, day_col, out = 'both'):\n",
    "    \"\"\"\n",
    "    Add the number of days as 2 additional columns to a tensor\n",
    "    \n",
    "    tensor_orig: sorted tensor containing a column with number of days\n",
    "    day_col: index of the column with days\n",
    "    \"\"\"\n",
    "    days = tensor_orig[:,day_col] # pull out day column\n",
    "    day_diff = np.abs(days[1:] - days[:-1]) # get days between\n",
    "    day_diff = np.expand_dims(day_diff, 1)\n",
    "\n",
    "    # create array with day_diff columns before and after\n",
    "    day_diff_before_after = np.concatenate((np.expand_dims(np.append(np.inf,day_diff), 1), \n",
    "                                            np.expand_dims(np.append(day_diff,np.inf), 1)), axis = 1)\n",
    "\n",
    "    day_diff_before_after = torch.from_numpy(day_diff_before_after)\n",
    "    \n",
    "    \n",
    "    if out == 'both':\n",
    "        tensor_day_diff = torch.concat((tensor_orig, day_diff_before_after),dim=1)\n",
    "    elif out == 'mean':\n",
    "        # get average distance (before & after)\n",
    "        day_diff_mean = torch.mean(day_diff_before_after, 1, True)\n",
    "        tensor_day_diff = torch.concat((tensor_orig, day_diff_mean),dim=1)\n",
    "    else:\n",
    "        print(\"ERROR\")\n",
    "    \n",
    "    return tensor_day_diff\n",
    "\n",
    "get_avg_days_to_nearest(tensor_orig, day_col = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnightly",
   "language": "python",
   "name": "dlnightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

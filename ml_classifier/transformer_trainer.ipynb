{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7217f6c2-4c4c-4e5c-9bb6-8687ed8f5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "import sys\n",
    "from datetime import timedelta\n",
    "# from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f95fcad-56ab-43b6-a50d-317152f7e186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>Subclass2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500</td>\n",
       "      <td>Crop(Double)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loc_id  Subclass2019\n",
       "0         0    Plantation\n",
       "1         1  Crop(Single)\n",
       "2         2  Crop(Single)\n",
       "3         3  Crop(Single)\n",
       "4         4    Plantation\n",
       "..      ...           ...\n",
       "496     496  Crop(Single)\n",
       "497     497  Crop(Single)\n",
       "498     498    Plantation\n",
       "499     499    Plantation\n",
       "500     500  Crop(Double)\n",
       "\n",
       "[501 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "proj_paths = [\"/Users/gopal/Google Drive/_Research/Research projects/ML/manclassify/app_data/Thailand\",\n",
    "              \"/Users/gopalpenny/Library/CloudStorage/GoogleDrive-gopalpenny@gmail.com/My Drive/_Research/Research projects/ML/manclassify/app_data/Thailand\"]\n",
    "\n",
    "proj_path = [path for path in proj_paths if os.path.exists(path)][0]\n",
    "\n",
    "class_path = os.path.join(proj_path,\"Thailand_classification\")\n",
    "ts_path = os.path.join(proj_path,\"Thailand_download_timeseries\")\n",
    "# pd.read_csv(\"\n",
    "os.listdir(class_path)\n",
    "\n",
    "loc_id = 0\n",
    "\n",
    "s2_csv_name = f\"pt_ts_loc{loc_id}_s2.csv\"\n",
    "s2_csv_name\n",
    "\n",
    "class_colname = 'Subclass2019'\n",
    "\n",
    "proj_normpath = os.path.normpath(proj_path)\n",
    "proj_dirname = proj_normpath.split(os.sep)[-1]\n",
    "proj_name = re.sub(\"_classification$\",\"\",proj_dirname)\n",
    "class_path = os.path.join(proj_path, proj_name + \"_classification\")\n",
    "ts_path = os.path.join(proj_path, proj_name + \"_download_timeseries\")\n",
    "pt_classes = pd.read_csv(os.path.join(class_path,\"location_classification.csv\"))\n",
    "pt_classes = pt_classes[['loc_id', class_colname]].dropna()\n",
    "\n",
    "pt_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadc6355-df65-4834-b219-1d3d6ead823f",
   "metadata": {},
   "source": [
    "## Generate the torch tensor dataset\n",
    "\n",
    "### Define function to read timeseries\n",
    "\n",
    "* Read timeseries\n",
    "* Filter timeseries to date range (+/- 60 days)\n",
    "* Remove observations with clouds\n",
    "* Take the mean value for each day (occurs when multiple overpasses happen on the same day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b32be994-4f4d-4666-9e96-9424cc71f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep dataset\n",
    "date_range = pd.to_datetime(['2019-06-01','2020-05-31'])\n",
    "\n",
    "def prep_s2_loc(loc_id, date_range, proj_path):\n",
    "    ts_path = os.path.join(proj_path,\"Thailand_download_timeseries\")\n",
    "    s2_csv_name = f\"pt_ts_loc{loc_id}_s2.csv\"\n",
    "    s2_csv_path = os.path.join(ts_path, s2_csv_name)\n",
    "    s2_ts = pd.read_csv(s2_csv_path)\n",
    "\n",
    "    # extract dates from image ids\n",
    "    s2_ts['datestr'] = [re.sub(\"(^[0-9]+)[a-zA-Z].*\",\"\\\\1\",x) for x in s2_ts.image_id]\n",
    "    s2_ts['date'] = pd.to_datetime(s2_ts.datestr, format = \"%Y%m%d\")\n",
    "\n",
    "    # subset to cloud-free days AND within date_range\n",
    "    s2_ts = s2_ts[(s2_ts.date >= date_range[0] - timedelta(days = 60)) & \n",
    "                  (s2_ts.date <= date_range[1] + timedelta(days = 60)) & \n",
    "                  (s2_ts.cloudmask == 0)]\n",
    "\n",
    "    # calculate day from startday\n",
    "    date_diff = (s2_ts.date - date_range[0])\n",
    "    s2_ts['day'] = [x.days for x in date_diff]\n",
    "    s2_ts['loc_id'] = loc_id\n",
    "\n",
    "    # select only predictor and position columns, return tensor\n",
    "    s2_ts_x = s2_ts[['loc_id','day','B8','B4','B3','B2']]\n",
    "    return s2_ts_x\n",
    "\n",
    "# s2_ts_loc125 = prep_s2_loc(125, date_range, proj_path)\n",
    "# s2_ts_loc125.groupby(['loc_id','day'],as_index = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336b48f-e6ff-468b-95cf-a1396e0e1768",
   "metadata": {},
   "source": [
    "### Get the torch tensor dataset (prep and save OR read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "38ac523f-49d7-4427-8d02-85e905ab73f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "if os.path.exists(os.path.join(proj_path, 's2_ts_prepped.pt')):\n",
    "    loc_ts_tor = torch.load(os.path.join(proj_path, 's2_ts_prepped.pt'))\n",
    "    \n",
    "else:\n",
    "    f = IntProgress(min=0, max=pt_classes.shape[0]) # instantiate the bar\n",
    "    display(f) # display the bar\n",
    "    \n",
    "    s2_ts_list = []\n",
    "    loc_id_list = []\n",
    "    for i in np.arange(pt_classes.shape[0]):\n",
    "        # loc_id = 499\n",
    "        # print(loc_id)\n",
    "        loc_id = pt_classes.loc_id.iloc[i]\n",
    "        # loc_id_list.append(loc_id)\n",
    "        s2_ts_loc = prep_s2_loc(loc_id, date_range, proj_path)\n",
    "        s2_ts_loc = s2_ts_loc.groupby(['loc_id','day'],as_index = False).mean()\n",
    "        s2_ts_tor = torch.tensor(s2_ts_loc.to_numpy())\n",
    "        s2_ts_list.append(s2_ts_tor)\n",
    "        f.value += 1\n",
    "        \n",
    "    loc_ts_tor = torch.cat(s2_ts_list)\n",
    "\n",
    "    torch.save(loc_ts_tor, os.path.join(proj_path, 's2_ts_prepped.pt'))\n",
    "\n",
    "sys.getsizeof(loc_ts_tor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87657506-61f2-446c-ab16-6d6a4b200b16",
   "metadata": {},
   "source": [
    "### Prep the dataset tensors\n",
    "\n",
    "* Subset to training classes (crops & plantations)\n",
    "* Check max number of rows\n",
    "* Normalize & center\n",
    "* Split loc_id into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e7b06a55-3c55-42e7-91fa-6ca3ea412559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All classes\n",
      "              loc_id\n",
      "Subclass2019        \n",
      "Crop(Double)      68\n",
      "Crop(Single)     278\n",
      "Forest             3\n",
      "Golf               1\n",
      "Mixed             20\n",
      "Plantation       109\n",
      "Unsure            17\n",
      "Urban              1\n",
      "Water              4\n",
      "\n",
      "Training dataset\n",
      "      loc_id  Subclass2019\n",
      "0         0    Plantation\n",
      "1         1  Crop(Single)\n",
      "2         2  Crop(Single)\n",
      "3         3  Crop(Single)\n",
      "4         4    Plantation\n",
      "..      ...           ...\n",
      "496     496  Crop(Single)\n",
      "497     497  Crop(Single)\n",
      "498     498    Plantation\n",
      "499     499    Plantation\n",
      "500     500  Crop(Double)\n",
      "\n",
      "[455 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('All classes')\n",
    "print(pt_classes.groupby('Subclass2019').count())\n",
    "\n",
    "train_classes = ['Crop(Double)','Crop(Single)','Plantation']\n",
    "pt_classes_ag = pt_classes[pt_classes['Subclass2019'].isin(train_classes)]\n",
    "print('\\nTraining dataset\\n',pt_classes_ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d2a727f0-a8c6-415c-b482-e19f70c5f571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of observations for any loc_id\n",
      "     loc_id  num_obs\n",
      "481     481       94\n"
     ]
    }
   ],
   "source": [
    "loc_ts_tor = loc_ts_tor[(loc_ts_tor[:,1] >= -30) & (loc_ts_tor[:,1] <= 395)]\n",
    "\n",
    "row_means= loc_ts_tor.mean(dim = 1)#.shape #.unsqueeze(0).repeat(5,1)\n",
    "loc_ts_tor = loc_ts_tor[~torch.isnan(row_means)]\n",
    "col_means= loc_ts_tor.mean(dim = 0)#.shape #.unsqueeze(0).repeat(5,1)\n",
    "col_std= loc_ts_tor.std(dim = 0)#.shape #.unsqueeze(0).repeat(5,1)\n",
    "col_means[[0,1]] = 0\n",
    "col_std[[0,1]] = 1\n",
    "\n",
    "loc_ts_tor_std = col_std.unsqueeze(0).repeat(loc_ts_tor.shape[0],1)\n",
    "loc_ts_tor_mean = col_means.unsqueeze(0).repeat(loc_ts_tor.shape[0],1)\n",
    "\n",
    "loc_ts_norm = (loc_ts_tor - loc_ts_tor_mean) / loc_ts_tor_std\n",
    "\n",
    "# get max of number of observations per location\n",
    "# idx = np.arange(loc_ts_norm.shape[0])\n",
    "loc_id = np.unique(loc_ts_norm[:,0])\n",
    "num_obs = pd.DataFrame({'loc_id' : np.unique(loc_ts_norm[:,0]).astype('int')})\n",
    "num_obs['num_obs'] = [loc_ts_norm[loc_ts_norm[:,0]==i,:].shape[0] for i in num_obs['loc_id']]\n",
    "print(\"Max number of observations for any loc_id\")\n",
    "print(num_obs.iloc[[num_obs['num_obs'].idxmax()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bd6b44a2-91e1-4bfd-8b55-cdba3b3f1f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "               loc_id\n",
      "Subclass2019        \n",
      "Crop(Double)      54\n",
      "Crop(Single)     222\n",
      "Plantation        87\n",
      "\n",
      "Testing\n",
      "               loc_id\n",
      "Subclass2019        \n",
      "Crop(Double)      14\n",
      "Crop(Single)      56\n",
      "Plantation        22\n"
     ]
    }
   ],
   "source": [
    "loc_train = pt_classes_ag.groupby('Subclass2019', group_keys = False).apply(lambda x: x.sample(frac = 0.8))\n",
    "loc_test = pt_classes_ag[~pt_classes_ag['loc_id'].isin(loc_train.loc_id)]\n",
    "print('Training\\n', loc_train.groupby('Subclass2019').count())\n",
    "print('\\nTesting\\n', loc_test.groupby('Subclass2019').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0bdda10b-384d-45fa-96d5-e83ec73a93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>Subclass2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>Crop(Double)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>Crop(Double)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>335</td>\n",
       "      <td>Crop(Double)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Crop(Double)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>449</td>\n",
       "      <td>Crop(Double)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>478</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>422</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>427</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loc_id  Subclass2019\n",
       "57       57  Crop(Double)\n",
       "162     162  Crop(Double)\n",
       "335     335  Crop(Double)\n",
       "48       48  Crop(Double)\n",
       "449     449  Crop(Double)\n",
       "..      ...           ...\n",
       "478     478    Plantation\n",
       "39       39    Plantation\n",
       "422     422    Plantation\n",
       "99       99    Plantation\n",
       "427     427    Plantation\n",
       "\n",
       "[363 rows x 2 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "848fb5a1-70fc-4de4-8d58-ebaea6adaa25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class s2Dataset(Dataset):\n",
    "    \"\"\"Sentinel 2 dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            proj_path (string): path to manclassify project\n",
    "        \"\"\"\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        # self.proj_path = proj_path\n",
    "        # proj_normpath = os.path.normpath(proj_path)\n",
    "        # proj_dirname = proj_normpath.split(os.sep)[-1]\n",
    "        # self.proj_name = re.sub(\"_classification$\",\"\",proj_dirname)\n",
    "        # self.class_path = os.path.join(proj_path, self.proj_name + \"_classification\")\n",
    "        # self.ts_path = os.path.join(proj_path, self.proj_name + \"_download_timeseries\")\n",
    "        # self.pt_classes = pd.read_csv(os.path.join(self.class_path,\"location_classification.csv\"))\n",
    "        # self.pt_classes = classes[['loc_id', class_colname]].dropna()\n",
    "        # self.classes = pd.unique(self.pt_classes[class_colname])\n",
    "        # self.labels = self.pt_classes.assign(val = 1).pivot_table(columns = class_colname, index = 'loc_id', values = 'val', fill_value= 0)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get loc_id\n",
    "        loc_id = self.y_train[idx,0]\n",
    "        self.last_loc_id = loc_id\n",
    "        \n",
    "        # select location id\n",
    "        x_loc = self.x_train[self.x_train[:,0]==loc_id]\n",
    "        x = x_loc[:,1:] # remove loc_id column\n",
    "        \n",
    "        # get one-hot encoding for the point as tensor\n",
    "        y =torch.tensor(y_train[idx,1:])\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.pt_classes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "744fef65-36d9-4b18-8044-d9e3b294757e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37, 5])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "y_train = (loc_train.assign(val = 1) \\\n",
    "  .pivot_table(columns = class_colname, index = 'loc_id', values = 'val', fill_value= 0) \\\n",
    "  .reset_index('loc_id').to_numpy())\n",
    "\n",
    "\n",
    "# loc_ts_norm[:,0]\n",
    "x_train = loc_ts_norm[torch.isin(loc_ts_norm[:,0],torch.tensor(y_train[:,0]).to(torch.float64)),:]\n",
    "\n",
    "s2_dataset = s2Dataset(x_train = x_train, y_train = y_train)\n",
    "x, y = s2_dataset.__getitem__(2)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "# sys.getsizeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad4e3d-3d90-45b7-8fcf-180c28fdcc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(s2_dataset, batch_size = 10, shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2bbd30-e297-47cf-a025-d8983de6c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac10e44-7ccd-4f4e-ab48-255648980338",
   "metadata": {},
   "source": [
    "## Old S2 pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8801cb4f-7504-4665-bd51-91a431e0d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class s2Dataset(Dataset):\n",
    "#     \"\"\"Sentinel 2 dataset\"\"\"\n",
    "    \n",
    "#     def __init__(self, proj_path, class_colname):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             proj_path (string): path to manclassify project\n",
    "#         \"\"\"\n",
    "#         self.proj_path = proj_path\n",
    "#         proj_normpath = os.path.normpath(proj_path)\n",
    "#         proj_dirname = proj_normpath.split(os.sep)[-1]\n",
    "#         self.proj_name = re.sub(\"_classification$\",\"\",proj_dirname)\n",
    "#         self.class_path = os.path.join(proj_path, self.proj_name + \"_classification\")\n",
    "#         self.ts_path = os.path.join(proj_path, self.proj_name + \"_download_timeseries\")\n",
    "#         self.pt_classes = pd.read_csv(os.path.join(self.class_path,\"location_classification.csv\"))\n",
    "#         self.pt_classes = classes[['loc_id', class_colname]].dropna()\n",
    "#         # self.pt_classes['loc_id'] = self.pt_classes['loc_id'] + 10.5 # for testing index only\n",
    "#         self.classes = pd.unique(self.pt_classes[class_colname])\n",
    "#         self.labels = self.pt_classes.assign(val = 1).pivot_table(columns = class_colname, index = 'loc_id', values = 'val', fill_value= 0)\n",
    "\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         loc_id = self.labels.index[idx]\n",
    "#         self.last_loc_id = loc_id\n",
    "        \n",
    "#         # select location id\n",
    "#         s2_ts_x = s2_ts[['B8','B4','B3','B2','day']]\n",
    "#         x = torch.tensor(s2_ts_x.to_numpy())\n",
    "        \n",
    "#         # get one-hot encoding for the point as tensor\n",
    "#         y = torch.tensor(self.labels.iloc[idx].to_numpy())\n",
    "        \n",
    "#         return x, y\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return self.pt_classes.shape[0]\n",
    "\n",
    "\n",
    "# proj_path = \"/Users/gopal/Google Drive/_Research/Research projects/ML/manclassify/app_data/Thailand\"\n",
    "# # date_rangeX = pd.to_datetime(['2019-06-01','2020-05-31'])\n",
    "# s2_dataset = s2Dataset(proj_path = proj_path, class_colname = 'Subclass2019')\n",
    "# x = s2_dataset.__getitem__(10)\n",
    "# sys.getsizeof(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnightly",
   "language": "python",
   "name": "dlnightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

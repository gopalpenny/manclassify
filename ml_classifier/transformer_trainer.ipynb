{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "7217f6c2-4c4c-4e5c-9bb6-8687ed8f5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "import sys\n",
    "from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "1f95fcad-56ab-43b6-a50d-317152f7e186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>Subclass2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>Crop(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>Plantation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>500</td>\n",
       "      <td>Crop(Double)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loc_id  Subclass2019\n",
       "0         0    Plantation\n",
       "1         1  Crop(Single)\n",
       "2         2  Crop(Single)\n",
       "3         3  Crop(Single)\n",
       "4         4    Plantation\n",
       "..      ...           ...\n",
       "496     496  Crop(Single)\n",
       "497     497  Crop(Single)\n",
       "498     498    Plantation\n",
       "499     499    Plantation\n",
       "500     500  Crop(Double)\n",
       "\n",
       "[501 rows x 2 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_path = \"/Users/gopal/Google Drive/_Research/Research projects/ML/manclassify/app_data/Thailand\"\n",
    "class_path = os.path.join(proj_path,\"Thailand_classification\")\n",
    "ts_path = os.path.join(proj_path,\"Thailand_download_timeseries\")\n",
    "# pd.read_csv(\"\n",
    "os.listdir(class_path)\n",
    "\n",
    "loc_id = 0\n",
    "\n",
    "s2_csv_name = f\"pt_ts_loc{loc_id}_s2.csv\"\n",
    "s2_csv_name\n",
    "\n",
    "class_colname = 'Subclass2019'\n",
    "\n",
    "proj_normpath = os.path.normpath(proj_path)\n",
    "proj_dirname = proj_normpath.split(os.sep)[-1]\n",
    "proj_name = re.sub(\"_classification$\",\"\",proj_dirname)\n",
    "class_path = os.path.join(proj_path, proj_name + \"_classification\")\n",
    "ts_path = os.path.join(proj_path, proj_name + \"_download_timeseries\")\n",
    "pt_classes = pd.read_csv(os.path.join(class_path,\"location_classification.csv\"))\n",
    "pt_classes = classes[['loc_id', class_colname]].dropna()\n",
    "\n",
    "pt_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "6ae77a50-5b7c-4440-b116-3de0540f0a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prep dataset\n",
    "date_range = pd.to_datetime(['2019-06-01','2020-05-31'])\n",
    "\n",
    "def prep_s2_loc(loc_id, date_range, proj_path):\n",
    "    ts_path = os.path.join(proj_path,\"Thailand_download_timeseries\")\n",
    "    s2_csv_name = f\"pt_ts_loc{loc_id}_s2.csv\"\n",
    "    s2_csv_path = os.path.join(ts_path, s2_csv_name)\n",
    "    s2_ts = pd.read_csv(s2_csv_path)\n",
    "\n",
    "    # extract dates from image ids\n",
    "    s2_ts['datestr'] = [re.sub(\"(^[0-9]+)[a-zA-Z].*\",\"\\\\1\",x) for x in s2_ts.image_id]\n",
    "    s2_ts['date'] = pd.to_datetime(s2_ts.datestr, format = \"%Y%m%d\")\n",
    "\n",
    "    # subset to cloud-free days AND within date_range\n",
    "    s2_ts = s2_ts[(s2_ts.date >= date_range[0]) & (s2_ts.date <= date_range[1]) & (s2_ts.cloudmask == 0)]\n",
    "\n",
    "    # calculate day from startday\n",
    "    date_diff = (s2_ts.date - date_range[0])\n",
    "    s2_ts['day'] = [x.days for x in date_diff]\n",
    "    s2_ts['loc_id'] = loc_id\n",
    "\n",
    "    # select only predictor and position columns, return tensor\n",
    "    s2_ts_x = s2_ts[['loc_id','day','B8','B4','B3','B2']]\n",
    "    return s2_ts_x\n",
    "\n",
    "if os.path.exists(os.path.join(proj_path, 's2_ts_prepped.pt')):\n",
    "    loc_ts_tor = torch.load(os.path.join(proj_path, 's2_ts_prepped.pt'))\n",
    "    \n",
    "else:\n",
    "    s2_ts_list = []\n",
    "    loc_id_list = []\n",
    "    for i in np.arange(pt_classes.shape[0]):\n",
    "        # loc_id = 499\n",
    "        # print(loc_id)\n",
    "        loc_id = pt_classes.loc_id.iloc[i]\n",
    "        # loc_id_list.append(loc_id)\n",
    "        s2_ts_loc = prep_s2_loc(loc_id, date_range, proj_path)\n",
    "        s2_ts_tor = torch.tensor(s2_ts_loc.to_numpy())\n",
    "        s2_ts_list.append(s2_ts_tor)\n",
    "        \n",
    "    loc_ts_tor = torch.cat(s2_ts_list)\n",
    "\n",
    "    torch.save(loc_ts_tor, os.path.join(proj_path, 's2_ts_prepped.pt'))\n",
    "\n",
    "sys.getsizeof(loc_ts_tor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "d2a727f0-a8c6-415c-b482-e19f70c5f571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 920.6667,  972.1667,  877.1667,  ..., 1228.3333, 1113.3333,\n",
       "        1425.8333], dtype=torch.float64)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_idx = loc_ts_tor[:,0] == 40\n",
    "loc_ts_tor[pt_idx]\n",
    "loc_ts_tor.mean(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "0bdda10b-384d-45fa-96d5-e83ec73a93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(os.path.join(proj_path, 's2_ts_prepped.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "848fb5a1-70fc-4de4-8d58-ebaea6adaa25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class s2Dataset(Dataset):\n",
    "    \"\"\"Sentinel 2 dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, proj_path, class_colname):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            proj_path (string): path to manclassify project\n",
    "        \"\"\"\n",
    "        self.proj_path = proj_path\n",
    "        proj_normpath = os.path.normpath(proj_path)\n",
    "        proj_dirname = proj_normpath.split(os.sep)[-1]\n",
    "        self.proj_name = re.sub(\"_classification$\",\"\",proj_dirname)\n",
    "        self.class_path = os.path.join(proj_path, self.proj_name + \"_classification\")\n",
    "        self.ts_path = os.path.join(proj_path, self.proj_name + \"_download_timeseries\")\n",
    "        self.pt_classes = pd.read_csv(os.path.join(self.class_path,\"location_classification.csv\"))\n",
    "        self.pt_classes = classes[['loc_id', class_colname]].dropna()\n",
    "        # self.pt_classes['loc_id'] = self.pt_classes['loc_id'] + 10.5 # for testing index only\n",
    "        self.classes = pd.unique(self.pt_classes[class_colname])\n",
    "        self.labels = self.pt_classes.assign(val = 1).pivot_table(columns = class_colname, index = 'loc_id', values = 'val', fill_value= 0)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        def\n",
    "        date_range = pd.to_datetime(['2019-06-01','2020-05-31'])\n",
    "        loc_id = self.labels.index[idx]\n",
    "        self.last_loc_id = loc_id\n",
    "        s2_csv_name = f\"pt_ts_loc{loc_id}_s2.csv\"\n",
    "        s2_csv_path = os.path.join(self.ts_path, s2_csv_name)\n",
    "        s2_ts = pd.read_csv(s2_csv_path)\n",
    "        \n",
    "        # extract dates from image ids\n",
    "        s2_ts['datestr'] = [re.sub(\"(^[0-9]+)[a-zA-Z].*\",\"\\\\1\",x) for x in s2_ts.image_id]\n",
    "        s2_ts['date'] = pd.to_datetime(s2_ts.datestr, format = \"%Y%m%d\")\n",
    "        \n",
    "        # subset to cloud-free days AND within date_range\n",
    "        s2_ts = s2_ts[(s2_ts.date >= date_range[0]) & (s2_ts.date <= date_range[1]) & (s2_ts.cloudmask == 0)]\n",
    "        \n",
    "        # calculate day from startday\n",
    "        date_diff = (s2_ts.date - date_range[0])\n",
    "        s2_ts['day'] = [x.days for x in date_diff]\n",
    "        \n",
    "        # select only predictor and position columns, return tensor\n",
    "        s2_ts_x = s2_ts[['B8','B4','B3','B2','day']]\n",
    "        x = torch.tensor(s2_ts_x.to_numpy())\n",
    "        \n",
    "        # get one-hot encoding for the point as tensor\n",
    "        y = torch.tensor(self.labels.iloc[idx].to_numpy())\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.pt_classes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ce55d9ca-f116-4b1a-ac05-aed0a1e1c74d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_path = \"/Users/gopal/Google Drive/_Research/Research projects/ML/manclassify/app_data/Thailand\"\n",
    "# date_rangeX = pd.to_datetime(['2019-06-01','2020-05-31'])\n",
    "s2_dataset = s2Dataset(proj_path = proj_path, class_colname = 'Subclass2019')\n",
    "x = s2_dataset.__getitem__(10)\n",
    "sys.getsizeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad4e3d-3d90-45b7-8fcf-180c28fdcc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(s2_dataset, batch_size = 10, shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2bbd30-e297-47cf-a025-d8983de6c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnightly",
   "language": "python",
   "name": "dlnightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
